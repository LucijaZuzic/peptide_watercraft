%% 
%% Copyright 2007-2024 Elsevier Ltd
%% 
%% This file is part of the 'Elsarticle Bundle'.
%% ---------------------------------------------
%% 
%% It may be distributed under the conditions of the LaTeX Project Public
%% License, either version 1.3 of this license or (at your option) any
%% later version.  The latest version of this license is in
%%    http://www.latex-project.org/lppl.txt
%% and version 1.3 or later is part of all distributions of LaTeX
%% version 1999/12/01 or later.
%% 
%% The list of all files belonging to the 'Elsarticle Bundle' is
%% given in the file `manifest.txt'.
%% 
%% Template article for Elsevier's document class `elsarticle'
%% with harvard style bibliographic references
%%
\documentclass[preprint,12pt]{elsarticle}

%% Use the option review to obtain double line spacing
%% \documentclass[preprint,review,12pt]{elsarticle}

%% Use the options 1p,twocolumn; 3p; 3p,twocolumn; 5p; or 5p,twocolumn
%% for a journal layout:
%% \documentclass[final,1p,times]{elsarticle}
%% \documentclass[final,1p,times,twocolumn]{elsarticle}
%% \documentclass[final,3p,times]{elsarticle}
%% \documentclass[final,3p,times,twocolumn]{elsarticle}
%% \documentclass[final,5p,times]{elsarticle}
%% \documentclass[final,5p,times,twocolumn]{elsarticle}

%% For including figures, graphicx.sty has been loaded in
%% elsarticle.cls. If you prefer to use the old commands
%% please give \usepackage{epsfig}

%% The amssymb package provides various useful mathematical symbols
\usepackage{amssymb}
%% The amsmath package provides various useful equation environments.
\usepackage{amsmath}
%% The amsthm package provides extended theorem environments
%% \usepackage{amsthm}

%% The lineno packages adds line numbers. Start line numbering with
%% \begin{linenumbers}, end it with \end{linenumbers}. Or switch it on
%% for the whole article with \linenumbers.
%% \usepackage{lineno}

%\usepackage[utf8]{inputenc}
%\usepackage[T1]{fontenc}
\usepackage{gensymb}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{multirow}

\journal{Journal of the Franklin Institute}

\begin{document}

\begin{frontmatter}

%% Title, authors and addresses

%% use the tnoteref command within \title for footnotes;
%% use the tnotetext command for theassociated footnote;
%% use the fnref command within \author or \affiliation for footnotes;
%% use the fntext command for theassociated footnote;
%% use the corref command within \author for corresponding author footnotes;
%% use the cortext command for theassociated footnote;
%% use the ead command for the email address,
%% and the form \ead[url] for the home page:
%% \title{Title\tnoteref{label1}}
%% \tnotetext[label1]{}
%% \author{Name\corref{cor1}\fnref{label2}}
%% \ead{email address}
%% \ead[url]{home page}
%% \fntext[label2]{}
%% \cortext[cor1]{}
%% \affiliation{organization={},
%%             addressline={},
%%             city={},
%%             postcode={},
%%             state={},
%%             country={}}
%% \fntext[label3]{}

\title{A Bayesian and Markov Chain Approach to Short-Term and Long-Term Personal Watercraft Trajectory Forecasting} %% Article title

%% use optional labels to link authors explicitly to addresses:
%% \author[label1,label2]{}
%% \affiliation[label1]{organization={},
%%             addressline={},
%%             city={},
%%             postcode={},
%%             state={},
%%             country={}}
%%
%% \affiliation[label2]{organization={},
%%             addressline={},
%%             city={},
%%             postcode={},
%%             state={},
%%             country={}}
%AUTHOR 1
\author[1,2]{Lucija \v{Z}u\v{z}i\'{c}}
\ead{lucija.zuzic@uniri.hr}

\author[1,3]{Ivan Dra\v{z}i\'{c}}
\ead{ivan.drazic@uniri.hr}

\author[1,3]{Loredana Sim\v{c}i\'{c}}
\ead{loredana.simcic@uniri.hr}

\author[1,2]{Franko Hr\v{z}i\'{c}}
\ead{franko.hrzic@riteh.uniri.hr}

\author[1,2]{Jonatan Lerga\corref{cor1}}%\fnref[label2]
\ead{jonatan.lerga@riteh.uniri.hr}
 
% Address/affiliation
\affiliation[1]{organization={Department of Computer Engineering, Faculty of Engineering, University of Rijeka},
addressline={Vukovarska 58}, 
%         city={Rijeka},
%citysep={Rijeka}, % Uncomment if no comma needed between city and postcode
postcode={51000 Rijeka}, 
country={Croatia}}

\affiliation[2]{organization={Center for Artificial Intelligence and Cybersecurity, University of Rijeka},
addressline={Radmile Matejcic 2}, 
postcode={51000 Rijeka}, 
country={Croatia}}

\affiliation[3]{organization={Department of Mathematics, Physics, and Foreign Languages, Faculty of Engineering, University of Rijeka},
addressline={Vukovarska 58}, 
%         city={Rijeka},
%citysep={Rijeka}, % Uncomment if no comma needed between city and postcode
postcode={51000 Rijeka}, 
country={Croatia}}

%\fntext[label2]{http://www.riteh.uniri.hr/osoba/jonatan-lerga}
% Corresponding author text
\cortext[cor1]{Corresponding author} 

%% Abstract
\begin{abstract}
In this work, vessel position is estimated using a Bayesian approach based on heading, speed, time intervals, and offsets of latitude and longitude. An additional approach using a Markov chain is presented. The trajectory data comes from a cloud-based marine watercraft tracking system that enables remote control of the vessels. Wave height and meteorological reports were used to evaluate the impact of weather on personal watercraft trajectories. One proposed approach to trajectory estimation uses the longitude and latitude offsets, while another uses the speed, heading, and actual time intervals. A long-term forecasting window of up to ten seconds is achieved by dividing trajectories into segments that do not overlap. The limitation this method faces in long-term forecasting inspires more sophisticated machine-learning approaches. The most successful estimation method used one or two previous actual values and a Bayesian approach, proving that using previously predicted values in a chain accumulates errors. Considering environmental variables did not improve the model, highlighting that small watercrafts operate well even in unstable sea states. This occurs because they generate and ride waves, having a larger impact than oceanic currents.
\end{abstract}

%%Graphical abstract
%\begin{graphicalabstract}
%\includegraphics{grabs}
%\end{graphicalabstract}

%%Research highlights
%\begin{highlights}
%\item Using a Bayesian and Markov chain approach for short-term and long-term forecasting
%\item Incorporating environmental variables for generating conditional probability models
%\item Comparing algorithms using one or two previous steps in future state estimation
%\item Comparing Bayesian or Markov chain models in future state estimation
%\item Demonstrating that the Bayesian model using two previous steps is the most successful
%\end{highlights}

%% Keywords
\begin{keyword}
personal watercraft \sep trajectory forecasting \sep Markov chain 
\end{keyword}

\end{frontmatter}

%% Add \usepackage{lineno} before \begin{document} and uncomment 
%% following line to enable line numbers
%% \linenumbers

%% main text
%%

% MAIN TEXT 
\section{Introduction}
%\label{sec:Introduction}
%\vspace{10pt}
More than $50000$ vessels use the sea channels for daily maritime transit, corresponding to $90\%$ cargo volume traded worldwide \citep{2022Kim}. Data on the movements of these ships is provided in abundance by various information systems and sensors and is difficult to interpret due to the significant increase in traffic volumes \citep{2013Kazemi}. This data is used for maritime surveillance and Marine Situational Awareness (MSA), essential components of several maritime traffic management systems. Anomaly detection is crucial for the system's operation, as anomalies can be linked to criminal activities or incidents (loss of navigation, engine damage, etc.).

Many publications, such as \citep{2009Chandola, 2011Martineau}, define anomalies differently. According to Roy et al. \citep{2008Roy}, the term "anomaly" has many meanings in different fields, which makes it a relatively nebulous concept with differing interpretations among experts. In this work, we can say that an anomaly is an event that does not fit into any one type or category \citep{2009Chandola}. Any deviation from the given models is interpreted by anomaly detection algorithms based on past data representing typical behavior. Unpredictable movements in open waters, abrupt stops before arriving at the destination, short travel distances, encounters with numerous other vessels, frequent looping, appearing to cross land based on transmitted data, deviations from planned routes, exceeding speed limits, violations of traffic regulations, etc. are all examples of irregular vessel behavior \citep{2014Mascaro, 2008Laxhammar}. Anomaly detection includes different techniques of finding notable events in many data-rich domains when the data is normal in the majority \citep{2009Chandola}.

Previously described anomalies \citep{2014Mascaro, 2008Laxhammar} concern larger vessels. Less work has been done on the behavior of smaller maritime vessels, which do not have to be equipped with a uniform reporting system. The risk of human error in the operation of personal vessels should be reduced, regardless of the vessel size, both on land and at sea. For this reason, several personal watercraft rental agencies have equipped their vessels with monitoring devices, such as those manufactured by OtoTrak \cite{ototrakOtoTrakTrack}. OtoTrak \cite{ototrakOtoTrakTrack} is a cloud-based marine watercraft tracking system that enables remote vehicle control. The rental agency can adjust the boundaries of the approved driving area based on latitude and longitude. Speed limits are enforced when a user leaves the designated area or approaches another vehicle. The module continuously transmits Global Positioning System (GPS) signals to facilitate these functions. Vehicles have been protected from collisions by a proximity-based speed limitation algorithm if they are equipped with the same system.

This paper defines a new technique that uses Bayesian probability forecasting and Markov chains for short-term and long-term forecasting of the driver's future behavior from historical data. The variables include heading, speed, time intervals, and the offset between latitude and longitude. The time interval is the time that has elapsed between records in the database to create a trajectory representing a single trip. One method for estimating the trajectory uses the longitude and latitude offset, while another uses the speed, heading, and actual time intervals. When estimating trajectories or a single variable, errors are evaluated using the root mean squared error. This was done to facilitate comparison with other studies. As we are concerned with prediction, not classification, a simple accuracy metric does not indicate actual performance.

The forecasts generated by the proposed approach might be used to prevent unnecessary speed limits in non-hazardous situations. They also ensure the safety of other drivers and passengers in maritime traffic. OtoTrak \cite{ototrakOtoTrakTrack} has granted the authors of this article access to the database. The database contains details of the rental locations, the vehicles themselves, and the data supplied for each trip, such as heading, speed, latitude, and longitude. Meteorological and sea state data from other public free sources was added to estimate the environmental impact on personal watercraft trajectories. Trajectories were split into non-overlapping segments of equal length to generate forecasts with a forecasting window of up to ten seconds. Python was used to develop the program code.

We found no other papers were published on personal watercraft trajectory forecasting in the examined literature, but many were found on other vehicles. In our paper, we contribute by:

\begin{enumerate}
    \item Using a Bayesian and Markov chain approach for short-term and long-term forecasting
    \item Incorporating environmental variables for generating conditional probability models
    \item Comparing algorithms using one or two previous steps in future state estimation
    \item Comparing Bayesian or Markov chain models in future state estimation
    \item Demonstrating that the Bayesian model using two previous steps is the most successful
\end{enumerate}

Contributions 3. and 4. are corroborated in Section~\ref{sec:Results}, while contribution 5. is elaborated upon in Section~\ref{sec:Conclusion}.

We hypothesize that these Bayesian model forecasts using two previous steps with actual values could be used in real-time, and the results of measuring response time support this conclusion. The proposed methods show significantly lower performance for long-term forecasting, so we plan to develop additional machine-learning methods to address these shortcomings.

The rest of the paper is structured as follows. Section~\ref{sec:Related} lists additional publications that identify anomalies in marine traffic. Section~\ref{sec:Dataset} describes the dataset. Section~\ref{sec:Methods} describes the methodology and evaluation metrics. Section~\ref{sec:Results} presents the results of this work. Section~\ref{sec:Discussion} offers a discussion of the implications of the results. Section~\ref{sec:Conclusion} summarises the main ideas in a conclusion.

\section{Related Work}
\label{sec:Related}
%\vspace{10pt}

The methods developed in this paper were influenced by studies in which behavioral anomalies or deviations from the normality paradigm were found in data related to the movement of larger ships. Numerous publications \citep{2016Coraluppi, 2018dAfflisio1, 2018Coscia, 2018Coscia1, 2018Forti, 2019Forti, 2020Forti, 2022Forti2, 2016Millefiori, 2021dAfflisio, 2021dAfflisio1} were found to use Ornstein–Uhlenbeck (OU) process methods for detecting anomalies in maritime traffic. The OU process is a stochastic stationary Gaussisan-Markov process, inspiring the use of Markov chains in the presented approach.

Markov chain methods have been successfully applied in robotic \cite{10130587}, and biological engineering \cite{10106394, 10309224} by constructing observable and detectable stochastic graphs, or Strong Structurally Observable Graphs (SSOG), similar to the approach used for watercraft trajectories in this paper. Complex networked contemporary technological systems, classical or quantum, regarding communication, transportation, power, or data transfer, also use Markov chains \cite{JAFARIZADEH2024107151}. Markovian jump systems (MJSs) \cite{YAO2024107194, SHEN2024107250, LIU2024107294}, Markovian jump complex dynamical networks (MJCDNs) \cite{ZHOU2024107251}, and Complex-valued Neural Networks (CVNNs) with Markov Jump Parameters (MJPs) \cite{ZHANG2024107324} are utilized with similar goals in mind, further supporting the proposed method.

Forti and his colleagues presented the Hybrid Bernoulli Random Set (HBRS), a new Bayesian technique applied to larger maritime vessels \citep{2018Forti, 2019Forti, 2020FortiO, 2022Forti2, 2022FortiO, 2022Forti1}, leading to a Bayesian approach considered in this experiment.

All studies cited use data from the Automatic Identification System (AIS) \citep{2016Ning}. AIS is a digital system that tracks the position of moving vessels in real-time and provides accurate and up-to-date static and dynamic information for vessel navigation, which is made publicly available. The data format of AIS contains information similar to the database used for this study, so this work is relevant to the current results.

Density-Based Spatial Clustering of Applications with Noise (DBSCAN) \citep{Ester1996ADA} is one of the most widely used density-based spatial clustering algorithms to identify anomalous ship behavior \citep{2018Coscia, 2018dAfflisio1, 2016Millefiori, Khan2004RealtimePO, 2021Pedroche} by classifying points and constructing a graph. Kernel Density Estimation (KDE) \citep{2013Pallotta, 2020Loi}, Gaussian Mixture Models (GMMs) \citep{2008Laxhammar} and multiple Ornstein-Uhlenbeck processes \citep{2019Forti, 2018Coscia1, 2014Pallotta} are some examples of probabilistic settings for constructing a normality model for each edge. The probability of a state is calculated to assess whether a new AIS track is abnormal. Typically, this is achieved by thresholding one of three parameters: the distance to the centroid of the feature vector representing the route \citep{Varlamis2019ANA}, the AIS trajectory probability obtained from the normality model \citep{2013Pallotta} or an adaptive Hybrid Bernoulli Filter (HBF) \citep{2019Forti}. These normality models served as a basis for the probability distributions used in this paper.

An event-triggered adaptive neural network (NN) \cite{10681283} can track and control autonomous underwater vehicle systems (AUVs). Similarly, nonlinear systems can be supervised using dynamic event-triggered adaptive fixed-time practical tracking control through a funnel function \cite{10681502}. This approach is much more sophisticated than the one used in this paper, and the authors plan to use a neural network approach for long-term prediction in further work.

Salami et al. \citep{salami2022wind} estimate wind speed distribution for a wind farm using a Multilayer Perceptron (MLP) and a Support Vector Machine (SVR). These approaches outperform numerical methods based on the Weibull distribution, the Justus Empirical Method (EMJ), and the Maximum Likelihood Method (MLM), indicating that a machine-learning model may better describe real-world phenomena.

\section{Dataset}
\label{sec:Dataset}
%\vspace{10pt}

Vessel trajectories used in this work were recorded in the USA, Canada, Greece, Spain, Portugal, and Croatia in 2023. Trajectories where the maximum time delay between data transmissions was five seconds or more were excluded. Trajectories flagged by OtoTrak \cite{ototrakOtoTrakTrack} as "ERROR" (missing data) or "TRACKING" (lower resolution recording) are not used. Latitude and longitude in each trajectory were converted to relative values, i.e. distances from the start. Since no trajectory covers a larger range of latitude and longitude than $0.1$, they were further normalized to a range of $0.1$ degrees of latitude and longitude. Trajectories on the negative side of the $x$ axis are mirrored on the $y$ axis, and trajectories on the negative side of the $y$ axis are mirrored on the $x$ axis. The times between records in the database are normalized to a range in milliseconds from the start of each trajectory.

The collection of trajectories for each vehicle equipped with an OtoTrak module \cite{ototrakOtoTrakTrack} was split in the ratio of $70:30$ or as close as possible to this ratio. If a vehicle has only one trajectory, it was included in the training set. A total of $384$ trajectories were used, of which $130$ were reserved for testing and $254$ for training. This resulted in the training dataset, comprising $66.15\%$ of the selected trajectory files, which was used to estimate the transition matrix for each variable described by a Markov chain. The remaining $33.85\%$ of the trajectory files were reserved for testing.

Figure~\ref{fig:all_train_mosaic} and Figure~\ref{fig:all_test_mosaic} show the training and testing trajectories. The number of training and test trajectories for each vehicle and the total number of training and test trajectories, separated by vehicle, can be seen in Table~\ref{tab:testtrain}. Figure~\ref{fig:all_train_mosaic} and Figure~\ref{fig:all_test_mosaic}. These trajectories represent real-world data, not simulations, are not stochastically generated, and were used to train and test the models.

\begin{figure}[!ht]
    \centering
    \includegraphics[width = 0.99 \linewidth]{all_train_mosaic.pdf}
    \caption{All of the used training trajectories. These trajectories represent real-world data, not simulations, and are not stochastically generated.}
    \label{fig:all_train_mosaic}
\end{figure}

\begin{figure}[!ht]
    \centering
    \includegraphics[width = 0.99 \linewidth]{all_test_mosaic.pdf}
    \caption{All of the used testing trajectories. These trajectories represent real-world data, not simulations, and are not stochastically generated.}
    \label{fig:all_test_mosaic}
\end{figure}
 
\begin{table}[!ht]
    \centering
    \begin{tabular}{|c|c|c|c|}
       \hline
        Vehicle & Train & Test & Total \\ \hline
        2 & 1 & 1 & 2 \\ \hline
        3 & 1 & 0 & 1 \\ \hline
        4 & 10 & 5 & 15 \\ \hline
        6 & 17 & 9 & 26 \\ \hline
        9 & 22 & 11 & 33 \\ \hline
        10 & 38 & 19 & 57 \\ \hline
        11 & 67 & 33 & 100 \\ \hline
        12 & 26 & 14 & 40 \\ \hline
        13 & 1 & 1 & 2 \\ \hline
        15 & 2 & 1 & 3 \\ \hline
        16 & 30 & 16 & 46 \\ \hline
        17 & 39 & 20 & 59 \\ \hline
        All & 254 & 130 & 384 \\ \hline
    \end{tabular}
    \caption{The training and test trajectories for each vehicle and the total number of training and test trajectories.}
    \label{tab:testtrain}
\end{table}

\subsection{Sea state}
%\label{subsec:Wave}

Data on sea surface wave significant height VHM0 in meters ($m$) was used to generate different conditional probability distributions for the forecasted variables in this study. The hypothesis is that the sea state, visible as waves, significantly changes driver behavior. Each wave height range identified in the training data was associated with a separate conditional probability distribution for each forecasted variable. These wave height ranges cover $0.1 \ km$ each, and are centered around numbers between $0 \ km$ and $1.1 \ km$.

The Copernicus Marine Environment Monitoring Service (CMEMS) and Copernicus Climate Change Service (C3S) offer satellite data on ocean states for various geographical locations and with different levels of preprocessing.

This study has been conducted using E.U. Copernicus Marine Service Information from "GLOBAL\_REANALYSIS\_WAV\_001\_032" \cite{https://doi.org/10.48670/moi-00022} (WAVERYS within the Global Monitoring and Forecasting Center for Croatia (Hrvatska) (GLO-HR MFC)) for the global wave reanalysis describing past sea states since 1993. WAVERYS accounts for oceanic currents from the GLORYS12 physical ocean reanalysis and assimilates significant wave height observed from historical altimetry missions and directional wave spectra from Sentinel 1 synthetic-aperture radar (SAR) from 2017 onwards. The data was obtained using the Météo-France WAve Model (MFWAM), a third-generation wave spectrum model. Average wave quantities are presented with a $0.2\degree$ spatial resolution.

The nearest wave height measurement point is matched with each point in a trajectory due to different spatial resolutions. Since values are added every three hours, and states for watercraft are stored approximately every second in analyzed files, the wave height with the smallest time difference was used for each point in a trajectory. This is done assuming that the observed wave height will not change significantly. When longer trajectory segments are forecast using a sliding window, the arithmetic average of the wave height is used to identify the range for estimating a conditional probability distribution.

\subsection{Meteorological features}
%\label{subsec:METAR}

Data on temperature in $\degree C$ (degrees Celsius) and wind speed in $m/s$ (meters per second) was also used to create various conditional probability distributions for the forecasted variables in this study. The assumption is that the sea state is more turbulent with larger wind speeds, while the driver would be less comfortable in lower temperatures, changing watercraft operating conditions. The temperature ranges associated with a separate conditional probability distribution cover $1 \ \degree C$ each, centered around whole numbers between $20 \ \degree C$ and $40 \ \degree C$. The wind speed ranges cover $1 \ km/s$ centered around whole numbers between $0 \ km/s$ and $10 \ km/s$.

Publicly available data on meteorological features was used to describe the watercraft trajectories. The website $rp5.ru$ \cite{rp5Description} publishes meteorological forecasts and historical data archives of Meteorological Aerodrome Report (METAR) reports in various file formats, such as \textit{.csv} or \textit{.xlsx}, for many measuring stations and airports. The nearest airport is matched with each watercraft rental location, listed in Table~\ref{tab:airport}.

\begin{table}[!ht]
    \centering
    \begin{tabular}{|c|c|c|c|}
        \hline
        Rental location & Airport ICAO code & Airport location \\ \hline
        1002 & LDSP & Split \\ \hline
        1868 & LPFR & Faro \\ \hline 
        2039, 1998 & LGSA & Souda / Chania \\ \hline
        1511 & LERI & Alcantarilla \\ \hline
        1314 & KMYF & Montgomery Field \\ \hline
        20 & LDDU & Dubrovnik \\ \hline
        1347 & KSLI & Los Alamitos \\ \hline
        2082 & KPNS & Pensacola / Regional \\ \hline
        1582 & KHWO & Hollywood / North Perry \\ \hline
    \end{tabular}
    \caption{The nearest airport used to obtain meteorological reports for each watercraft rental location, and the airport International Civil Aviation Organization (ICAO) code.}
    \label{tab:airport}
\end{table}

Data on dew point in degrees Celsius and the associated relative humidity expressed as a percentage were not used in the analysis since they are closely related to temperature. Air pressure data expressed in $mmHg$ (millimeters of mercury) was omitted from the experiment because of the difference in altitude between the sea level and measuring stations.

Information regarding wind direction, vertical visibility, clouds, thunder, and precipitation was not used because it is descriptive, not numerical. The average wind speed in the last ten minutes is not included in the reports from all measuring stations, so it is not included in the analysis.

Measurements of meteorological features are added every half hour or every full hour, less frequently than for trajectories. The procedure for merging datasets with different temporal resolutions, described for wave height in the previous section, was applied again, resolving this problem.

\section{Methods}
\label{sec:Methods}
%\vspace{10pt}

\subsection{Markov Chains}
%\label{subsec:markov}
%\vspace{10pt}

Many processes with temporal duration and uncertain outcomes require a generalization of the concept of random variables so that the temporal dimension is also included. If we consider a family of random variables that depend on time, we arrive at the concept of a stochastic process. In this paper, the movement of a personal watercraft is studied and the trajectory representing this movement is considered a stochastic process.

A stochastic process $\{X_{t}|t\in T\}$ is uniquely determined by the family of all its $n$-dimensional distributions $x_{t_{1}}, \dots, x_{t_{n}}$, for each $n \in N$ and each time $t_{1}, \dots, t_{n} \in T$. Knowledge of the family of finite-dimensional distributions is very demanding in practice. Only one-, two- and three-dimensional distributions are examined in this paper.

In this paper, we deal with a type of stochastic process called Markov processes. A Markov process $\{X_{t}|t\in T\}$ is a stochastic process that satisfies the Markov property \citep{Gagniuc}, where the probability of transitioning to any future state depends solely on the current state and not the sequence of preceding states. The described Markov property is formalized in Equation~\ref{eqn1} for all $t_{1} < t_{2} < \dots < t_{n} < t$. A stochastic process becomes a Markov chain when, in addition to the Markov property, it has a discrete set of states and discrete time.

\begin{equation} \label{eqn1}
    \begin{aligned}
        & P(a<X_{t}<b|X_{t_{1}}=x_{1}, X_{t_{2}}=x_{2}, \dots, X_{t_{n}}=x_{n}) = \\
     &P(a<X_{t}<b|X_{t_{n}}=x_{n})  
    \end{aligned}
\end{equation}  

Using a Markov process, future outcomes can be estimated based solely on the current state of the system $x_{n}$ at time $t_{n}$. Such estimates are as accurate as those that could be made knowing the complete history of the process \citep{citeulike:1220946}.

This paper uses stationary Markov processes. In a narrower sense, the process $\{X_{t}|t\in T\}$ is stationary if, for each $h$, the distributions of the random vectors $(X_{t_{1}}, \dots, X_{t_{n}})$ and $(X_{t_{1 + h}}, \dots, X_{t_{n + h}})$ are the same. Time-homogeneous Markov chains are processes in which the transition probability from one state to another is independent of the time at which the process is observed. A necessary and sufficient condition for a time-homogeneous Markov chain to be stationary \citep{Gagniuc2017-jf} is that the initial distribution of the random vectors is a stationary distribution of the Markov chain.

The system state changes  (called transitions) \citep{Gagniuc} are defined by the stochastic matrix of transition probabilities $\Pi:=(p_{ij})$, where $p_{ij}$ defined in Equation~\ref{eqn2} describes the transition probabilities of one state into another in one step of the Markov chain. For the matrix $\Pi$, Equation~\ref{eqn3} holds.

\begin{equation} \label{eqn2}
    \begin{aligned}
       p_{ij}:=P(X_{n+1}=j|X_{n}=i)
    \end{aligned}
\end{equation}  

\begin{equation} \label{eqn3}
    \begin{aligned}
        \sum_{j}p_{ij}=\sum_{j}P(X_{n+1}=j|X_{n}=i)=1
    \end{aligned}
\end{equation}   

The Markov chain is completely described if the matrix $\Pi$ and the distribution of the random variable $X_{0}$ are known. Such a distribution is a vector of initial probabilities, as formalized in Equation~\ref{eqn4}, where Equation~\ref{eqn5} holds for each element.
  
\begin{equation} \label{eqn4}
    \begin{aligned}
     p(0)=(p_{1}(0),p_{2}(0), \dots, p_{i}(0))
    \end{aligned}
\end{equation}  

\begin{equation} \label{eqn5}
    \begin{aligned}
     p_{i}(0):=P(X_{0}=i)
    \end{aligned}
\end{equation}  

A state $i$ is called ergodic if it is aperiodic and positively recurrent. In other words, a state $i$ is ergodic if it is repetitive, has a period of $1$, and has a finite mean recurrence time. If all states in an irreducible Markov chain are ergodic, then the chain is ergodic. Some authors refer to all irreducible, positive recurrent Markov chains as ergodic or aperiodic \citep{Parzen1962-oe}. The Markov chains constructed in this paper are ergodic.

\subsection{Bayesian Approaches and Markov Chains Used For State Estimation}
%\vspace{10pt}

The variables used for state estimation by Markov chains include the offset rounded to ten decimal places in the $x$ direction (longitude) and $y$ direction (latitude). In addition, the speed at the location (recorded by the OtoTrak module  \cite{ototrakOtoTrakTrack} in kilometers per hour) is rounded to the nearest whole number. Also used was the heading (measured by the OtoTrak module  \cite{ototrakOtoTrakTrack}) or the offset from the north ($90\degree$, positive direction of the $y$ axis), which increases from east to west and has a value between $0\degree$ and $360\degree$. In addition, the interval between two recorded points was modeled and rounded to three decimal places or milliseconds.

Both a Markov chain using the previous forecast and a Bayesian approach using real-world values are tested to demonstrate that using actual values instead of estimates for further forecasting is more accurate since the error does not accumulate. Methods using only one instead of two previous states and either forecasted or actual values for additional forecasting were also used to prove that adding another previous state is beneficial.

For the first state, an estimate of the probability, i.e. the relative frequency of a certain state $P(X_{n}), \quad n = 1$, was used.

It was assumed that the Markov property is valid in its classical form for the second state estimation, as formalized in Equation~\ref{eqn6}, where $\{X_{t}|t\in T\}$ is the estimated value.

\begin{equation} \label{eqn6}
    \begin{aligned}
        P(X_{n}|X_{n-1}, \dots X_{0}) = P(X_{n}|X_{n-1}), \quad n = 2
    \end{aligned}
\end{equation}

An equivalent Bayesian method using actual real-world values is formalized in Equation~\ref{eqn7}, where $\{X_{t}|t\in T\}$ is the estimated value and $\{A_{t}|t\in T\}$ is the actual value of a variable.

\begin{equation} \label{eqn7}
    \begin{aligned}
        P(X_{n}|A_{n-1},..,A_{0}) = P(X_{n}|A_{n-1}), \quad n = 2
    \end{aligned}
\end{equation}

For each variable examined in this paper, it was additionally assumed that the Markov property is valid for a set of two consecutive states. Each state from the third state up to path length $d$ was estimated using the two previous values of a variable as formalized in Equation~\ref{eqn8}, where $\{X_{t}|t\in T\}$ is the estimated value.

\begin{equation} \label{eqn8}
    \begin{aligned}
        & P((X_{n},X_{n-1})|X_{n-1}, \dots X_{0}) = \\
        & P((X_{n},X_{n-1})|X_{n- 1},X_{n-2}), \quad n \in \left[3, d\right]
    \end{aligned}
\end{equation}

The same expression using actual real-world values in a Bayesian method is formalized in Equation~\ref{eqn9}, where $\{X_{t}|t\in T\}$ is the estimated value and $\{A_{t}|t\in T\}$ is the actual value of a variable. This forecasting method is not based on the previous forecast but on real-world values.

\begin{equation} \label{eqn9}
    \begin{aligned}
        & P((X_{n},A_{n-1})|A_{n-1}, \dots A_{0}) = \\
        & P((X_{n},A_{n-1})|A_{n- 1},A_{n-2}), \quad n \in \left[3, d\right]
    \end{aligned}
\end{equation}

The Markov chain estimation of the variables in the first, second, and subsequent states using two previous states and forecasted values is illustrated in Algorithm~\ref{alg:alg3}. The Bayesian forecasting method using two previous states and actual values is described in Algorithm~\ref{alg:alg4}. The Markov chain forecasting method using one previous state and forecasted values is visible in Algorithm~\ref{alg:alg5}. A Bayesian method using one previous state and actual values is explained in Algorithm~\ref{alg:alg6}.

\begin{algorithm}[H] 
\caption{Estimating variables using forecasted values and two previous states in a Markov chain}
\begin{algorithmic}\label{alg:alg3}
\FORALL{$n <= d$}  
\IF{$n == 1$} \STATE $X_{n} \gets \textbf{random sample } P(X_{n})$ \ENDIF
\IF{$n == 2$} \STATE $X_{n} \gets \textbf{random sample } P(X_{n}|X_{n-1})$ \ENDIF
\IF{$n > 2$} \STATE $X_{n} \gets \textbf{random sample } P((X_{n},X_{n-1})|X_{n-1},X_{n-2})$ \ENDIF
\ENDFOR
\end{algorithmic}
%\label{alg3}
\end{algorithm}

\begin{algorithm}[H] 
\caption{Estimating variables using actual values and two previous states in a Bayesian method}
\begin{algorithmic}\label{alg:alg4}
\FORALL{$n <= d$}  
\IF{$n == 1$} \STATE $X_{n} \gets \textbf{random sample } P(X_{n})$ \ENDIF
\IF{$n == 2$} \STATE $X_{n} \gets \textbf{random sample } P(X_{n}|A_{n-1})$ \ENDIF
\IF{$n > 2$} \STATE $X_{n} \gets \textbf{random sample } P((X_{n},A_{n-1})|A_{n-1},A_{n-2})$ \ENDIF
\ENDFOR
\end{algorithmic}
%\label{alg4}
\end{algorithm}

\begin{algorithm}[H] 
\caption{Estimating variables using forecasted values and one previous state in a Markov chain}
\begin{algorithmic}\label{alg:alg5}
\FORALL{$n <= d$}  
\IF{$n == 1$} \STATE $X_{n} \gets \textbf{random sample } P(X_{n})$ \ENDIF
\IF{$n >= 2$} \STATE $X_{n} \gets \textbf{random sample } P(X_{n}|X_{n-1})$ \ENDIF
\ENDFOR
\end{algorithmic}
%\label{alg5}
\end{algorithm}

\begin{algorithm}[H] 
\caption{Estimating variables using actual values and one previous state in a Bayesian method}
\begin{algorithmic}\label{alg:alg6}
\FORALL{$n <= d$}  
\IF{$n == 1$} \STATE $X_{n} \gets \textbf{random sample } P(X_{n})$ \ENDIF
\IF{$n >= 2$} \STATE $X_{n} \gets \textbf{random sample } P(X_{n}|A_{n-1})$ \ENDIF
\ENDFOR
\end{algorithmic}
%\label{alg6}
\end{algorithm}

\subsection{Storing Transition Matrices}
%\vspace{10pt}

The data for the $\Pi$ matrix is written in the form of a dictionary data structure in which the origin and destination states of the transition are the keys and the values in the dictionary represent the transition probabilities. The dimensions of the $\Pi$ matrix for each variable for short-term and long-term forecasting are given in Table~\ref{tab:dimmatr}. The dimensions of the matrix at first increase when splitting the trajectory into longer segments, due to the larger number of theoretically possible sequences. However, the dimensions decrease for segments longer than five seconds because there is less training data and individual segments when each one is longer.
 
\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|}
		\hline
		\multicolumn{6}{|c|}{Short-term forecasting matrix dimensions} \\ \hline
		Variable & $1 \ s$ & $2 \ s$ & $3 \ s$ & $4 \ s$ & $5 \ s$ \\ \hline
        Heading & $361$ & $18376$ & $45885$ & $46696$ & $39189$ \\ \hline
        $y$ offset & $401$ & $11190$ & $31862$ & $36965$ & $35736$ \\ \hline
        Speed & $84$ & $1653$ & $13034$ & $24680$ & $26742$ \\ \hline
        $x$ offset & $479$ & $15247$ & $36977$ & $40827$ & $37568$ \\ \hline
		\multicolumn{6}{|c|}{Long-term forecasting matrix dimensions} \\ \hline
		Variable & $6 \ s$ & $7 \ s$ & $8 \ s$ & $9 \ s$ & $10 \ s$ \\ \hline
        Heading & $32895$ & $28232$ & $24699$ & $21942$ & $19744$ \\ \hline
        $y$ offset & $31931$ & $27991$ & $24617$ & $21909$ & $19721$ \\ \hline
        Speed & $25643$ & $23811$ & $21957$ & $20239$ & $18609$ \\ \hline
        $x$ offset & $32522$ & $28119$ & $24650$ & $21915$ & $19723$ \\ \hline
	\end{tabular}
	\caption{The dimensions of the $\Pi$ matrix for each variable for short-term and long-term forecasting.}
	\label{tab:dimmatr}
\end{table}
  
\subsection{Estimating a Trajectory}
%\label{subsec:EstimatingTrajectory}
%\vspace{10pt}

It is possible to directly add the offsets in $x$ and $y$ direction to estimate the trajectory, as shown in Algorithm~\ref{alg:alg1}.

\begin{algorithm}[H] 
\caption{Estimating longitude and latitude using $x$ and $y$ offset}\label{alg:alg1}
\begin{algorithmic} 
\STATE $long_{1} \gets 0$
\STATE $lat_{1} \gets 0$ 
\FORALL{$2 <= n <= d$}  
\STATE $long_{n} \gets long_{n-1} + x_{n}$ 
\STATE $lat_{n} \gets lat_{n-1} + y_{n}$ 
\ENDFOR
\end{algorithmic}
%\label{alg1}
\end{algorithm}
 
The second method uses speed, time, and heading along with trigonometric functions to obtain latitude and longitude, given in Algorithm~\ref{alg:alg2}.
 
\begin{algorithm}[H] 
\caption{Estimating longitude and latitude using speed, heading, and time}\label{alg:alg2}
\begin{algorithmic} 
\STATE $long_{1} \gets 0$
\STATE $lat_{1} \gets 0$
\FORALL{$2 <= n <= d$} 
\STATE $\overline{\theta_{n}} \gets (90\degree - \theta_{n} + 360\degree) \bmod 360\degree$ 
\IF{$\textbf{mirrored around the y axis }$} \STATE $\overline{\theta_{n}} \gets (180\degree - \overline{\theta_{n}} + 360\degree) \bmod 360\degree$  \ENDIF 
\IF{$\textbf{mirrored around the x axis }$} \STATE $\overline{\theta_{n}} \gets 360\degree - \overline{\theta_{n}}$ \ENDIF 
\STATE $\overline{v_{n}} \gets v_{n} / (111 \times 0.1 \times 3600)$
\STATE $long_{n} \gets long_{n-1} + \cos{\left(\overline{\theta_{n}}\right)} \times \overline{v_{n}} \times t_{n}$ 
\STATE $lat_{n} \gets lat_{n-1} + \sin{\left(\overline{\theta_{n}}\right)} \times \overline{v_{n}} \times t_{n}$ 
\ENDFOR
\end{algorithmic}
%\label{alg2}
\end{algorithm}

\section{Results}
\label{sec:Results}
%\vspace{10pt}

Root mean squared error (RMSE) is used to evaluate performance when estimating each variable or a trajectory for short-term and long-term forecasting with a forecasting horizon of up to $10 \ s$. This was done to enable further comparison with competing approaches that estimate trajectories of land vehicles using neural networks. Accuracy is not measured since the generated models are not used for classification, and the results would not fairly show performance. To evaluate real-time responsiveness and robustness for trajectory forecasting in dynamic maritime environments, execution time is included for each variable and different forecasting horizons.

\subsection{Execution Time}
%\label{subsec:direction_results}
%\vspace{10pt}

An additional execution time metric provides a more comprehensive view of the model's suitability for practical applications. The execution time for generating $1000$ random points from the estimated conditional probability distributions for different variables is given in Table~\ref{tab:timeno} for short-term and long-term forecasting with a forecasting horizon of up to $10 \ s$. All execution times are under $2 \ s$ for $1000$ points, proving the models could be practically applicable. The execution time increases with a longer forecasting horizon, following the established trend for $\Pi$ matrix size listed in Table~\ref{tab:dimmatr}.

The simulation was done on \textit{Windows} 11 using the AMD Radeon RX 6600 graphics processing unit (GPU), $16$ GB of random-access memory (RAM), and the AMD Ryzen 5 PRO 4650G central processing unit (CPU) with $6$ cores.

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|}
        \hline
        \multicolumn{6}{|c|}{Short-term forecasting execution time} \\
        \multicolumn{6}{|c|}{in milliseconds ($ms$) for the 2-step model} \\ \hline
        Variable & $1 \ s$ & $2 \ s$ & $3 \ s$ & $4 \ s$ & $5 \ s$ \\ \hline
        Heading & $205.66$ & $221.69$ & $668.25$ & $1020.16$ & $1258.07$ \\ \hline
        $x$ offset & $212.27$ & $209.26$ & $279.71$ & $602.53$ & $1067.43$ \\ \hline
        $y$ offset & $220.6$ & $208.12$ & $268.49$ & $431.79$ & $856.71$ \\ \hline
        Speed & $203.04$ & $211.49$ & $213.63$ & $337.65$ & $421.28$ \\ \hline
        \multicolumn{6}{|c|}{Long-term forecasting execution time} \\
        \multicolumn{6}{|c|}{in milliseconds ($ms$) for the 2-step model} \\ \hline
        Variable & $6 \ s$ & $7 \ s$ & $8 \ s$ & $9 \ s$ & $10 \ s$ \\ \hline
        Heading & $1411.34$ & $1332.21$ & $1202.55$ & $1170.32$ & $1468.65$ \\ \hline
        $x$ offset & $1186.35$ & $1284.33$ & $1445.0$ & $1287.98$ & $1514.25$ \\ \hline
        $y$ offset & $1207.48$ & $1155.56$ & $1386.67$ & $1283.6$ & $1280.98$ \\ \hline
        Speed & $462.6$ & $945.3$ & $957.9$ & $1123.94$ & $1071.18$ \\ \hline
        \multicolumn{6}{|c|}{Short-term forecasting execution time} \\
        \multicolumn{6}{|c|}{in milliseconds ($ms$) for the 1-step model} \\ \hline
        Variable & $1 \ s$ & $2 \ s$ & $3 \ s$ & $4 \ s$ & $5 \ s$ \\ \hline
        Heading & $288.01$ & $206.69$ & $698.6$ & $891.76$ & $1292.31$ \\ \hline
        $x$ offset & $282.65$ & $238.98$ & $333.37$ & $572.1$ & $1067.08$ \\ \hline
        $y$ offset & $286.08$ & $244.83$ & $252.67$ & $414.11$ & $856.76$ \\ \hline
        Speed & $206.45$ & $275.15$ & $237.01$ & $353.3$ & $390.23$ \\ \hline
        \multicolumn{6}{|c|}{Long-term forecasting execution time} \\
        \multicolumn{6}{|c|}{in milliseconds ($ms$) for the 1-step model} \\ \hline
        Variable & $6 \ s$ & $7 \ s$ & $8 \ s$ & $9 \ s$ & $10 \ s$ \\ \hline
        Heading & $1457.04$ & $1270.22$ & $1368.55$ & $1427.28$ & $1462.2$ \\ \hline
        $x$ offset & $1202.8$ & $1369.86$ & $1338.11$ & $1260.95$ & $1357.51$ \\ \hline
        $y$ offset & $906.32$ & $1138.93$ & $1329.21$ & $1150.19$ & $1171.33$ \\ \hline
        Speed & $521.9$ & $823.61$ & $901.67$ & $885.96$ & $1145.27$ \\ \hline
    \end{tabular}
	\caption{The execution time in milliseconds ($ms$) for generating $1000$ random points from the estimated distributions for different variables using short-term and long-term forecasting with a forecasting horizon of up to $10 \ s$.}
	\label{tab:timeno}
\end{table}

\subsection{Results for Heading}
%\label{subsec:direction_results}
%\vspace{10pt}

Figure~\ref{fig:best_RMSE_var} contains the average RMSE for all variables estimated on the testing dataset by various models and forecasting times.

\begin{figure}[!ht]
	\centering
	\includegraphics[width = 0.99 \linewidth]{best_RMSE_var.pdf}
	\caption{The average RMSE for all variables estimated on the testing dataset by different models and forecasting times.}
	\label{fig:best_RMSE_var}
\end{figure}

Table~\ref{tab:best_direction_RMSE} lists the average RMSE in $\degree$, for the heading estimated on the testing dataset by different models and forecasting times.

\begin{table}[!ht]
	\centering
	\resizebox{\linewidth}{!}{
		\begin{tabular}{|c|c|c|c|c|c|}
			\hline
			\multicolumn{6}{|c|}{Short-term forecasting RMSE in $\degree$ for heading} \\ \hline
			Model & $1 \ s$ & $2 \ s$ & $3 \ s$ & $4 \ s$ & $5 \ s$ \\ \hline
			1-step Bayes & $59.556$ & $67.375$ & $114.113$ & $\mathbf{141.237}$ & $146.603$ \\ \hline
			2-step Bayes & $\mathbf{51.607}$ & $\mathbf{66.974}$ & $\mathbf{114.051}$ & $141.728$ & $146.303$ \\ \hline
			Wave 2-step Markov & $132.75$ & $148.223$ & $147.682$ & $146.442$ & $\mathbf{145.469}$ \\ \hline
			\multicolumn{6}{|c|}{Long-term forecasting RMSE in $\degree$ for heading} \\ \hline
			Model & $6 \ s$ & $7 \ s$ & $8 \ s$ & $9 \ s$ & $10 \ s$ \\ \hline
			1-step Markov & $148.115$ & $149.133$ & $\mathbf{144.265}$ & $148.542$ & $150.055$ \\ \hline
			Temperature 2-step Markov & $\mathbf{143.236}$ & $146.903$ & $148.558$ & $146.838$ & $146.867$ \\ \hline
			Wave 2-step Markov & $145.664$ & $\mathbf{146.196}$ & $148.51$ & $147.169$ & $147.919$ \\ \hline
			Wind 2-step Bayes & $147.6$ & $146.637$ & $146.01$ & $147.359$ & $\mathbf{146.001}$ \\ \hline
			Wind 2-step Markov & $146.109$ & $148.079$ & $147.538$ & $\mathbf{145.794}$ & $146.307$ \\ \hline
		\end{tabular}
	}
	\caption{The average RMSE in $\degree$, for the heading estimated on the testing dataset by different models and forecasting times. The numbers in bold indicate the lowest values and best models for each forecasting time.}
	\label{tab:best_direction_RMSE}
\end{table}

The 2-step Bayes model reaches the lowest RMSE for heading and a forecasting time of $1$, $2$, and $3 \ s$. The average values equal $51.607 \degree$, $66.974 \degree$, and $114.051 \degree$ respectively.

The 1-step Bayes model has the lowest RMSE for heading and a forecasting time of $4 \ s$ with an average value of $141.237 \degree$.

The Wave 2-step Markov model provides the lowest RMSE for heading and a forecasting time of $5$ and $7 \ s$. The average values amount to $145.469 \degree$, and $146.196 \degree$ respectively.

The Temperature 2-step Markov model achieves the lowest RMSE for heading and a forecasting time of $6 \ s$. The average value is $143.236 \degree$.

The 1-step Markov model demonstrates the lowest RMSE for heading and a forecasting time of $8 \ s$. The average value equals $144.265 \degree$.

The Wind 2-step Markov model attains the lowest RMSE for heading and a forecasting time of $9 \ s$. The average value amounts to $145.794 \degree$.

The Wind 2-step Bayes model achieves the lowest RMSE for heading and a forecasting time of $10 \ s$ with an average value equaling $146.001 \degree$.

\subsection{Results for $y$ Offset}
%\label{subsec:latitude_results}
%\vspace{10pt}

Table~\ref{tab:best_latitude_RMSE} exhibits the average RMSE in $\degree$ ($\times 10^{-4}$), for the $y$ offset estimated on the testing dataset by different models and forecasting times.

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|}
		\hline
		\multicolumn{6}{|c|}{Short-term forecasting RMSE in $\degree$ ($\times 10^{-4}$) for $y$ offset} \\ \hline
		Model & $1 \ s$ & $2 \ s$ & $3 \ s$ & $4 \ s$ & $5 \ s$ \\ \hline
		1-step Bayes & $1.335$ & $2.594$ & $\mathbf{5.387}$ & $6.431$ & $6.813$ \\ \hline
		2-step Bayes & $\mathbf{1.105}$ & $\mathbf{2.588}$ & $5.411$ & $\mathbf{6.382}$ & $\mathbf{6.753}$ \\ \hline
		\multicolumn{6}{|c|}{Long-term forecasting RMSE in $\degree$ ($\times 10^{-4}$) for $y$ offset} \\ \hline
		Model & $6 \ s$ & $7 \ s$ & $8 \ s$ & $9 \ s$ & $10 \ s$ \\ \hline
		2-step Markov & $6.903$ & $7.08$ & $7.248$ & $\mathbf{6.946}$ & $7.08$ \\ \hline
		Temperature 1-step Markov & $7.06$ & $\mathbf{6.842}$ & $7.154$ & $7.022$ & $7.016$ \\ \hline
		Wind 1-step Bayes & $6.978$ & $6.993$ & $7.035$ & $7.015$ & $\mathbf{6.949}$ \\ \hline
		Wind 2-step Bayes & $6.948$ & $7.068$ & $\mathbf{6.958}$ & $7.042$ & $7.042$ \\ \hline
		Wind 2-step Markov & $\mathbf{6.867}$ & $7.234$ & $7.134$ & $7.104$ & $7.044$ \\ \hline
	\end{tabular}
	\caption{The average RMSE in \degree ($\times 10^{-4}$), for the $y$ offset estimated on the testing dataset by different models and forecasting times. The numbers in bold indicate the lowest values and best models for each forecasting time.}
	\label{tab:best_latitude_RMSE}
\end{table}

The lowest RMSE for $y$ offset and a forecasting time of $1$, $2$, $4$, and $5 \ s$ is for the 2-step Bayes model. The average values equal $1.105 \times 10^{-4} \ \degree$, $2.588 \times 10^{-4} \ \degree$, $6.382 \times 10^{-4} \ \degree$, and $6.753 \times 10^{-4} \ \degree$ respectively.

The lowest average RMSE for $y$ offset and a forecasting time of $3 \ s$ is $5.387 \times 10^{-4} \ \degree$, reached by the 1-step Bayes model.

The lowest average RMSE for $y$ offset and a forecasting time of $6 \ s$ is achieved by the Wind 2-step Markov model and amounts to $6.867 \times 10^{-4} \ \degree $.

The Temperature 1-step Markov model accounts for the lowest RMSE for $y$ offset and a forecasting time of $7 \ s$ with an average value equaling $6.842 \times 10^{-4} \ \degree$.

The lowest RMSE for $y$ offset and a forecasting time of $8 \ s$ is attained by the Wind 2-step Bayes model with an average value of $6.958 \times 10^{-4} \ \degree$.

For $y$ offset and a forecasting time of $9 \ s$, the 2-step Markov model demonstrates the lowest RMSE with an average value equaling $6.946 \times 10^{-4} \ \degree$.

Regarding $y$ offset and a forecasting time of $10 \ s$, the Wind 1-step Bayes model achieves the lowest RMSE   with an average value of $6.949 \times 10^{-4} \ \degree$.

\subsection{Results for $x$ Offset}
%\label{subsec:longitude_results}
%\vspace{10pt}

Table~\ref{tab:best_longitude_RMSE} shows the average RMSE in $\degree$ ($\times 10^{-4}$), for the $x$ offset estimated on the testing dataset by different models and forecasting times.

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|}
		\hline
		\multicolumn{6}{|c|}{Short-term forecasting RMSE in $\degree$ ($\times 10^{-4}$) for $x$ offset} \\ \hline
		Model & $1 \ s$ & $2 \ s$ & $3 \ s$ & $4 \ s$ & $5 \ s$ \\ \hline
		1-step Bayes & $1.776$ & $3.755$ & $\mathbf{7.474}$ & $8.597$ & $8.999$ \\ \hline
		2-step Bayes & $\mathbf{1.504}$ & $\mathbf{3.735}$ & $7.485$ & $\mathbf{8.593}$ & $9.04$ \\ \hline
		Wave 2-step Markov & $7.645$ & $8.414$ & $8.944$ & $9.244$ & $\mathbf{8.937}$ \\ \hline
		\multicolumn{6}{|c|}{Long-term forecasting RMSE in $\degree$ ($\times 10^{-4}$) for $x$ offset} \\ \hline
		Model & $6 \ s$ & $7 \ s$ & $8 \ s$ & $9 \ s$ & $10 \ s$ \\ \hline
		Wave 1-step Markov & $9.114$ & $9.137$ & $\mathbf{8.942}$ & $9.197$ & $\mathbf{8.877}$ \\ \hline
		Wave 2-step Markov & $9.132$ & $\mathbf{9.091}$ & $9.064$ & $9.153$ & $9.135$ \\ \hline
		Wind 2-step Markov & $\mathbf{8.951}$ & $9.312$ & $9.11$ & $\mathbf{8.947}$ & $9.188$ \\ \hline
	\end{tabular}
	\caption{The average RMSE in \degree ($\times 10^{-4}$), for the $x$ offset estimated on the testing dataset by different models and forecasting times. The numbers in bold indicate the lowest values and best models for each forecasting time.}
	\label{tab:best_longitude_RMSE}
\end{table}

Concerning $x$ offset and a forecasting time of $1$, $2$, and $4 \ s$, the 2-step Bayes model reaches the lowest RMSE. The average values are $1.504 \times 10^{-4} \ \degree$, $3.735 \times 10^{-4} \ \degree$, and $8.593 \times 10^{-4} \ \degree$ respectively.

Observing $x$ offset and a forecasting time of $3 \ s$, the 1-step Bayes model exhibits the lowest RMSE with an average value equaling $7.474 \times 10^{-4} \ \degree$.

The lowest average RMSE values for $x$ offset amount to $8.937 \times 10^{-4} \ \degree$, and $9.091 \times 10^{-4} \ \degree$ for a forecasting time of $5$ and $7 \ s$ respectively. The Wave 2-step Markov model is used for these results.

When using a forecasting time of $6$ and $9 \ s$, the Wind 2-step Markov model achieves the lowest RMSE for $x$ offset. The average values equal $8.951 \times 10^{-4} \ \degree$, and $8.947 \times 10^{-4} \ \degree$ respectively.

Viewing $x$ offset and a forecasting time of $8$ and $10 \ s$, the lowest average RMSE values are $8.942 \times 10^{-4} \ \degree$ and $8.877 \times 10^{-4} \ \degree$ respectively. The Wave 1-step Markov model reaches these results.

\subsection{Results for Speed}
%\label{subsec:speed_results}
%\vspace{10pt}

Table~\ref{tab:best_speed_RMSE} contains the average RMSE in $km/h$, for the speed estimated on the testing dataset by different models and forecasting times.

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|}
		\hline
		\multicolumn{6}{|c|}{Short-term forecasting RMSE in $km/h$ for speed} \\ \hline
		Model & $1 \ s$ & $2 \ s$ & $3 \ s$ & $4 \ s$ & $5 \ s$ \\ \hline
		2-step Bayes & $\mathbf{4.12}$ & $\mathbf{5.98}$ & $\mathbf{10.56}$ & $\mathbf{17.14}$ & $\mathbf{20.07}$ \\ \hline
		\multicolumn{6}{|c|}{Long-term forecasting RMSE in $km/h$ for speed} \\ \hline
		Model & $6 \ s$ & $7 \ s$ & $8 \ s$ & $9 \ s$ & $10 \ s$ \\ \hline
		1-step Bayes & $\mathbf{21.4}$ & $22.22$ & $\mathbf{22.66}$ & $\mathbf{23.13}$ & $23.22$ \\ \hline
		2-step Bayes & $21.41$ & $\mathbf{22.15}$ & $22.86$ & $23.26$ & $23.51$ \\ \hline
		Wave 2-step Markov & $24.64$ & $23.73$ & $24.0$ & $23.57$ & $\mathbf{23.18}$ \\ \hline
	\end{tabular}
	\caption{The average RMSE in $km/h$, for the speed estimated on the testing dataset by different models and forecasting times. The numbers in bold indicate the lowest values and best models for each forecasting time.}
	\label{tab:best_speed_RMSE}
\end{table}

The 2-step Bayes model demonstrates the lowest RMSE for speed and a forecasting time of $1$, $2$, $3$, $4$, $5$, and $7 \ s$. The average values are $4.12 \ km/h$, $5.98 \ km/h$, $10.56 \ km/h$, $17.14 \ km/h$, $20.07 \ km/h$, and $22.15 \ km/h$ respectively.

The 1-step Bayes model represents the lowest RMSE for speed and a forecasting time of $6$, $8$, and $9 \ s$. The values amount to $21.4 \ km/h$, $22.66 \ km/h$, and $23.13 \ km/h$ respectively.

The Wave 2-step Markov model accounts for the lowest RMSE for speed and a forecasting time of $10 \ s$, supported by an average value of $23.18 \ km/h$.

\subsection{Results for Trajectories Estimated Using $x$ and $y$ Offset}
%\label{subsec:no_abs_results}
%\vspace{10pt}

Figure~\ref{fig:best_RMSE_traj} demonstrates the average RMSE for all trajectories in the testing dataset generated using different trajectory estimation methods, models, and forecasting times.

\begin{figure}[!ht]
	\centering
	\includegraphics[width = 0.99 \linewidth]{best_RMSE_traj.pdf}
	\caption{The average RMSE for all trajectories in the testing dataset generated using different trajectory estimation methods, models, and forecasting times.}
	\label{fig:best_RMSE_traj}
\end{figure}

Table~\ref{tab:best_no_abs_RMSE} provides the average RMSE in $\degree$ ($\times 10^{-3}$), for the trajectories in the testing dataset estimated using $x$ and $y$ offset, different models, and forecasting times.

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|}
		\hline
		\multicolumn{6}{|c|}{Short-term forecasting RMSE in $\degree$ ($\times 10^{-3}$) for trajectories} \\ 
		\multicolumn{6}{|c|}{estimated using $x$ and $y$ offset} \\ \hline
		Model & $1 \ s$ & $2 \ s$ & $3 \ s$ & $4 \ s$ & $5 \ s$ \\ \hline
		1-step Bayes & $\mathbf{5.207}$ & $\mathbf{18.164}$ & $\mathbf{46.026}$ & $64.928$ & $\mathbf{70.401}$ \\ \hline
		2-step Bayes & $5.47$ & $18.866$ & $46.868$ & $\mathbf{61.627}$ & $73.634$ \\ \hline
		\multicolumn{6}{|c|}{Long-term forecasting RMSE in $\degree$ ($\times 10^{-3}$) for trajectories} \\ 
		\multicolumn{6}{|c|}{estimated using $x$ and $y$ offset} \\ \hline
		Model & $6 \ s$ & $7 \ s$ & $8 \ s$ & $9 \ s$ & $10 \ s$ \\ \hline
		1-step Bayes & $75.886$ & $76.391$ & $77.721$ & $80.636$ & $\mathbf{78.266}$ \\ \hline
		2-step Bayes & $75.029$ & $\mathbf{73.814}$ & $78.567$ & $79.659$ & $81.261$ \\ \hline
		Wind 1-step Bayes & $79.428$ & $74.407$ & $\mathbf{76.48}$ & $\mathbf{72.218}$ & $82.144$ \\ \hline
		Wind 2-step Bayes & $\mathbf{72.742}$ & $76.42$ & $85.445$ & $78.751$ & $83.404$ \\ \hline
	\end{tabular}
	\caption{The average RMSE in $\degree$ ($\times 10^{-3}$), for the trajectories in the testing dataset estimated using $x$ and $y$ offset, different models, and forecasting times. The numbers in bold indicate the lowest values and best models for each forecasting time.}
	\label{tab:best_no_abs_RMSE}
\end{table}

The 1-step Bayes model accounts for the lowest RMSE for trajectories estimated using $x$ and $y$ offset, and a forecasting time of $1$, $2$, $3$, $5$, and $10 \ s$. This is cooroborated by average values of $5.207 \times 10^{-3} \ \degree$, $18.164 \times 10^{-3} \ \degree$, $46.026 \times 10^{-3} \ \degree$, $70.401 \times 10^{-3} \ \degree$, and $78.266 \times 10^{-3} \ \degree$ respectively.

The 2-step Bayes model shows the lowest RMSE using a forecasting time of $4$ and $7 \ s$ for trajectories estimated using $x$ and $y$ offset. The supporting average values equal $61.627 \times 10^{-3} \ \degree$ and $73.814 \times 10^{-3} \ \degree$ respectively.

The Wind 2-step Bayes model attains the lowest RMSE for trajectories estimated using $x$ and $y$ offset, and a forecasting time of $6 \ s$ with an average value equaling $72.742 \times 10^{-3} \ \degree$.

The Wind 1-step Bayes model reaches the lowest RMSE for trajectories estimated using $x$ and $y$ offset, and a forecasting time of $8$ and $9 \ s$. The appropriate average values amount to $76.48 \times 10^{-3} \ \degree$, and $72.218 \times 10^{-3} \ \degree$ respectively.

\subsection{Results for Trajectories Estimated Using Speed, Heading, and Actual Time Intervals}
%\label{subsec:speed_actual_dir_results}
%\vspace{10pt}

Table~\ref{tab:best_speed_actual_dir_RMSE} informs of the average RMSE in $\degree$ ($\times 10^{-2}$), for the trajectories in the testing dataset estimated using speed, heading, and actual time intervals, different models, and forecasting times.

\begin{table}[!ht]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|}
		\hline
		\multicolumn{6}{|c|}{Short-term forecasting RMSE in $\degree$ ($\times 10^{-2}$) for trajectories} \\ 
		\multicolumn{6}{|c|}{estimated using speed, heading, and actual time intervals} \\ \hline
		Model & $1 \ s$ & $2 \ s$ & $3 \ s$ & $4 \ s$ & $5 \ s$ \\ \hline
		1-step Bayes & $\mathbf{1.438}$ & $\mathbf{1.966}$ & $\mathbf{3.936}$ & $5.755$ & $\mathbf{6.192}$ \\ \hline
		2-step Bayes & $1.462$ & $1.967$ & $4.0$ & $\mathbf{5.412}$ & $6.463$ \\ \hline
		\multicolumn{6}{|c|}{Long-term forecasting RMSE in $\degree$ ($\times 10^{-2}$) for trajectories} \\ 
		\multicolumn{6}{|c|}{estimated using speed, heading, and actual time intervals} \\ \hline
		Model & $6 \ s$ & $7 \ s$ & $8 \ s$ & $9 \ s$ & $10 \ s$ \\ \hline
		1-step Bayes & $6.778$ & $6.81$ & $6.953$ & $7.225$ & $\mathbf{6.938}$ \\ \hline
		2-step Bayes & $6.629$ & $\mathbf{6.52}$ & $7.033$ & $7.072$ & $7.229$ \\ \hline
		Wind 1-step Bayes & $7.084$ & $6.663$ & $\mathbf{6.796}$ & $\mathbf{6.453}$ & $7.422$ \\ \hline
		Wind 2-step Bayes & $\mathbf{6.557}$ & $6.868$ & $7.698$ & $7.105$ & $7.73$ \\ \hline
	\end{tabular}
	\caption{The average RMSE in $\degree$ ($\times 10^{-2}$), for the trajectories in the testing dataset estimated using speed, heading, and actual time intervals, different models, and forecasting times. The numbers in bold indicate the lowest values and best models for each forecasting time.}
	\label{tab:best_speed_actual_dir_RMSE}
\end{table}

The 1-step Bayes model exhibits the lowest RMSE for trajectories estimated using speed, heading, and actual time intervals, and a forecasting time of $1$, $2$, $3$, $5$, and $10 \ s$. The average values validating this statement are $1.438 \times 10^{-2} \ \degree$, $1.966 \times 10^{-2} \ \degree$, $3.936 \times 10^{-2} \ \degree$, $6.192 \times 10^{-2} \ \degree$, and $6.938 \times 10^{-2} \ \degree$ respectively.

The 2-step Bayes model provides the lowest RMSE for trajectories estimated using speed, heading, and actual time intervals, and a forecasting time of $4$ and $7 \ s$. The average values equal $5.412 \times 10^{-2} \ \degree$  and $6.52 \times 10^{-2} \ \degree$ respectively, strengthening this conclusion.

The Wind 2-step Bayes model demonstrates the lowest RMSE for trajectories estimated using speed, heading, and actual time intervals, and a forecasting time of $6 \ s$ with an average value of $6.557 \times 10^{-2} \ \degree$.

The Wind 1-step Bayes model shows the lowest RMSE for trajectories estimated using speed, heading, and actual time intervals, and a forecasting time of $8$, and $9 \ s$. The average values amount to $6.796 \times 10^{-2} \ \degree$ and $6.453 \times 10^{-2} \ \degree$ respectively.

\subsection{Comparison with Existing Neural Network Models}

An important test measure for this simulation is comparison with other existing models for trajectory prediction. The RMSE values for models predicting $y$ offset and speed for personal automobiles driving on a highway are compared to the results of this study in Table~\ref{tab:lateral_position} and Table~\ref{tab:longitudinal_speed}.

The bagged model represents the arithmetic average of the outputs from the four best models marked by a * in Table~\ref{tab:lateral_position} and Table~\ref{tab:longitudinal_speed}. Generated by Altché and de La Fortelle, bagging is usually superior to a single model. The work by Altché and de La Fortelle \cite{altche2017lstm} done using Long Short-Term Memory (LSTM) Recurrent Neural Network (RNN) models was compared with a Multi-Layer Perceptron (MLP) without a recurrent layer created by Liu et al. \cite{liu2014vehicle}.

The $y$ offset values generated by tested models were converted from values representing $\degree$ latitude to meters ($m$) for comparison with the literature. Speeds from this study in $km/h$ were converted to meters per second ($m/s$) for the same reason. Competing models generated in other studies perform significantly better, but they use much more training data, and a more complex neural network approach, requiring a longer computational time.

\begin{table}[!ht]
	\centering
    \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
        \hline
        Model & $1 \ s$ & $2 \ s$ & $3 \ s$ & $4 \ s$ & $6 \ s$ & $8 \ s$ & $10 \ s$ \\ \hline
        Reference* & $0.71$ & $0.99$ & $1.25$ & $1.49$ & $2.1$ & $2.6$ & $2.96$ \\ \hline
        Type* & $0.65$ & $0.88$ & $1.05$ & $1.25$ & $1.75$ & $2.28$ & $2.74$ \\ \hline
        No f f* & $0.67$ & $0.91$ & $1.16$ & $1.44$ & $1.98$ & $2.43$ & $2.84$ \\ \hline
        No bypass & $1.5$ & $1.5$ & $1.55$ & $1.66$ & $2.05$ & $2.5$ & $2.89$ \\ \hline
        Bypass before & $0.78$ & $0.9$ & $1.06$ & $1.26$ & $1.76$ & $2.3$ & $2.78$ \\ \hline
        Lin. activ. & $0.77$ & $1.1$ & $1.34$ & $1.56$ & $2.08$ & $2.58$ & $2.94$ \\ \hline
        2 LSTMs & $0.76$ & $1.14$ & $1.42$ & $1.71$ & $2.22$ & $2.72$ & $3.17$ \\ \hline
        3 dense* & $0.73$ & $0.87$ & $1.04$ & $1.25$ & $1.76$ & $2.3$ & $2.77$ \\ \hline
        Bagged & $\mathbf{0.64}$ & $\mathbf{0.81}$ & $\mathbf{0.98}$ & $\mathbf{1.18}$ & $\mathbf{1.63}$ & $\mathbf{2.08}$ & $\mathbf{2.48}$ \\ \hline 
        1 step Bayes & $1.33$ & $1.68$ & $2.98$ & $4.78$ & $5.95$ & $6.3$ & $6.45$ \\ \hline
        2 step Bayes & $1.15$ & $1.66$ & $2.93$ & $4.76$ & $5.95$ & $6.35$ & $6.53$ \\ \hline
        Wave 2 step Markov & $6.69$ & $6.65$ & $6.58$ & $6.52$ & $6.84$ & $6.67$ & $6.44$ \\ \hline
    \end{tabular}
    \caption{RMSE in meters per second ($m/s$) for neural network models from the literature \cite{altche2017lstm} (top) and the tested models (bottom) for speed.}
    \label{tab:longitudinal_speed}
\end{table}

\begin{table}[!ht]
	\centering
    \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
        \hline
        Model & $1 \ s$ & $2 \ s$ & $3 \ s$ & $4 \ s$ & $6 \ s$ & $8 \ s$ & $10 \ s$ \\ \hline
        Reference* & $\mathbf{0.11}$ & $0.25$ & $\mathbf{0.33}$ & $\mathbf{0.4}$ & $0.53$ & $0.6$ & $0.73$ \\ \hline
        Type* & $0.39$ & $0.39$ & $0.44$ & $0.48$ & $0.53$ & $0.63$ & $0.69$ \\ \hline
        No f f* & $0.14$ & $\mathbf{0.24}$ & $0.33$ & $0.41$ & $0.54$ & $0.65$ & $0.76$ \\ \hline
        No bypass & $0.8$ & $0.82$ & $0.85$ & $0.88$ & $0.93$ & $0.97$ & $1.03$ \\ \hline
        Bypass before & $0.33$ & $0.38$ & $0.43$ & $0.46$ & $0.52$ & $0.61$ & $0.68$ \\ \hline
        Lin. activ. & $1.38$ & $1.39$ & $1.4$ & $1.42$ & $1.46$ & $1.51$ & $1.56$ \\ \hline
        2 LSTMs & $1.25$ & $1.26$ & $1.28$ & $1.29$ & $1.33$ & $1.37$ & $1.41$ \\ \hline
        3 dense* & $0.34$ & $0.38$ & $0.44$ & $0.5$ & $0.59$ & $0.7$ & $0.72$ \\ \hline
        MLP \cite{liu2014vehicle} & $0.11$ & $0.32$ & $0.71$ & $/$ & $/$ & $/$ & $/$ \\ \hline
        Bagged & $0.17$ & $0.25$ & $0.33$ & $0.4$ & $\mathbf{0.46}$ & $\mathbf{0.57}$ & $\mathbf{0.65}$ \\ \hline
        1 step Bayes & $1.48$ & $2.88$ & $5.98$ & $7.14$ & $7.78$ & $7.92$ & $7.91$ \\ \hline
        2 step Bayes & $1.23$ & $2.87$ & $6.01$ & $7.08$ & $7.77$ & $7.92$ & $7.86$ \\ \hline
        Wind 1 step Bayes & $2.4$ & $5.54$ & $7.32$ & $7.67$ & $7.75$ & $7.81$ & $7.71$ \\ \hline
        Wind 2 step Bayes & $2.43$ & $5.55$ & $7.36$ & $7.53$ & $7.71$ & $7.72$ & $7.82$ \\ \hline
        Wind 2 step Markov & $5.97$ & $6.86$ & $7.53$ & $7.66$ & $7.62$ & $7.92$ & $7.82$ \\ \hline
    \end{tabular}
    \caption{RMSE in meters ($m$) for neural network models from the literature \cite{altche2017lstm, liu2014vehicle} (top) and the tested models (bottom) for $y$ offset.}
    \label{tab:lateral_position}
\end{table}

\section{Discussion}
\label{sec:Discussion}
%\vspace{10pt}

When using any method with a forecasting horizon of $1$ or $2 \ s$, the Bayesian model with two previous states with actual values achieved the lowest RMSE, which means other methods are ineffective. This is corroborated by the numbers in Table~\ref{tab:best_direction_RMSE}, Table~\ref{tab:best_latitude_RMSE}, Table~\ref{tab:best_longitude_RMSE}, and Table~\ref{tab:best_speed_RMSE}. This additionally supports the assumption that errors accumulate in Markov chains that use previous estimates and that an additional previous value boosts forecasting power. The RMSE was not lower for short-term forecasting with the addition of meteorological data and wave height, while all models were unsuccessful for long-term prediction. This disproves the hypothesis that personal watercraft are significantly affected by weather or wave state. The observed vessels operate in shallow waters near ports and narrow areas, where waves generated by oceanic currents are smaller than those caused by vehicle operation. 

Using the Bayesian model and two states, the estimated $y$ offset has a lower RMSE in Table~\ref{tab:best_latitude_RMSE} than the estimated $x$ offset in Table~\ref{tab:best_longitude_RMSE}, indicating more accurate estimates. This is most likely caused by more frequent negative values of $x$ offset than $y$ offset, shown in Table~\ref{tab:latitude_no_abs}  and Table~\ref{tab:longitude_no_abs} in \ref{sec:Transition}. The estimated heading in Table~\ref{tab:best_direction_RMSE} never achieved a RMSE below $59\degree$, almost one-third of a $180\degree$ range, indicating less accurate estimates. This is most likely due to sudden turns that include acceleration and deceleration. The RMSE increases dramatically for all variables in long-term forecasting, indicating this simple method is not powerful enough to capture long-term variable dependencies. This is highlighted in comparison with forecasts by Altché and de La Fortelle done for land vehicles on highways, as presented in Table~\ref{tab:lateral_position} and Table~\ref{tab:longitudinal_speed}.

When using any trajectory estimation method with a forecasting horizon of less than $4 \ s$ or equal to $5 \ s$, the Bayesian model with one previous state with actual values achieved the lowest RMSE. The Bayesian model with two previous states with actual values achieved the lowest RMSE for any method with a forecasting horizon equal to $4 \ s$. Table~\ref{tab:best_no_abs_RMSE}, Table~\ref{tab:best_speed_actual_dir_RMSE} support this using numerical values. Once again, this means that the only method worth utilizing in practice is the Bayesian approach using one or two previous states to estimate a single future step. The trajectory estimation method using $x$ and $y$ offset instead of speed, heading, and the actual time interval has a lower RMSE in $\degree$ of longitude and latitude for any forecasting horizon. This confirms the results when individual variables are examined in isolation. The RMSE values for each variable can be compared to what Altché et al. \citep{altche2017lstm} achieved for land vehicles using neural networks and Long Short-Term Memory (LSTM), with an average RMSE of $70$ centimeters for the lateral position ten seconds in the future, and an average RMSE of $3$ meters per second for the longitudinal velocity with the same horizon, which our method cannot accomplish. This inspired our future research into additional machine-learning methods for long-term prediction.

\section{Conclusion}
\label{sec:Conclusion}
%\vspace{10pt}

This paper uses a short-term and long-term Bayesian and Markov chain approach to forecast future values of different variables and estimate a driver's behavior based on historical data. Either one or two previous states are utilized. Equal-length non-overlapping segments of trajectories are used for forecasting up to ten seconds into the future.

Sea state data on significant wave height and meteorological data on temperature and wind speed were used to estimate conditional probability distributions of trajectory variables for different environmental factor ranges. The estimated trajectory variables include latitude and longitude offset, speed, heading, and time intervals. The first method for trajectory estimation uses the latitude and longitude offsets. The second method uses the estimated heading and speed, combined with actual time intervals between records in the database.

According to the obtained RMSE, the offset in the $x$ direction is slightly less successfully estimated than the $y$ direction. Speed has a very high RMSE compared to the variable range due to sudden turns and deviations from a straight path.

Using a Bayesian approach and two previous actual values without considering environmental data, all estimated variables achieved the lowest NRMSE for a $1$ or $2$ forecasting window. The RMSE was not lower for short-term forecasting when considering temperature, wind speed, or wave height. This leads us to conclude that the vessel type studied in this experiment is not severely impacted by sea state due to their design, construction, and the areas where they operate. The most successful trajectory estimation method tested for short-term forecasting uses the $x$ and $y$ offset and a Bayesian approach with one or two actual values. Markov chain accumulates errors of previous estimates, providing a possible explanation for these results. 

All models were less successful than other existing work on long-term prediction of trajectories. As a guide for further work, we plan to apply machine learning methods for trajectory forecasting and compare them with the results obtained here and in competing machine learning studies by other authors.

% conflicts of interest
\section*{Declaration of competing interest}
The authors declare no conflict of interest.

\section*{CRediT authorship contribution statement}

\textbf{Lucija \v{Z}u\v{z}i\'{c}:} Conceptualization, Methodology, Software, Validation, Investigation, Data Curation, Writing -- Original Draft, Visualization.

\textbf{Ivan Dra\v{z}i\'{c}:} Conceptualization, Methodology, Software, Validation, Investigation, Data Curation, Writing -- Original Draft, Visualization.

\textbf{Loredana Sim\v{c}i\'{c}:} Methodology, Formal analysis, Investigation, Writing -- Review \& Editing.

\textbf{Franko Hr\v{z}i\'{c}:} Conceptualization, Validation, Formal analysis, Investigation, Resources, Writing -- Original Draft, Writing -- Review \& Editing, Supervision.

\textbf{Jonatan Lerga:} Conceptualization, Methodology, Validation, Formal analysis, Investigation, Resources, Writing -- Original Draft, Writing -- Review \& Editing, Supervision, Project administration, Funding acquisition.

% acknowledgment
\section*{Funding}
This work was fully supported by the EU Horizon 2020 project INNO2MARE under the no. 101087348, Ministry of Education, Science and Innovation of Montenegro grant no. 04-082/23-2527/1, and University of Rijeka projects no. uniri-iskusni-tehnic-23-11, uuniri-iskusni-tehnic-23-83, and uniri-zip-2103-4-22.

\appendix
\section{Transition Matrices For Estimated Variables}
\label{sec:Transition}
%\vspace{10pt}

Due to many possible states, the range of states for each estimated variable was divided into two ranges, and the transition probabilities for the states in each range were added up to create a two-state matrix presented in the paper.

The frequency of each state for $x$ offset ranges and the first and second-order transition matrices can be seen in Table~\ref{tab:longitude_no_abs}. The same values for the $y$ offset ranges can be seen in Table~\ref{tab:latitude_no_abs}.

The same values are listed in Table~\ref{tab:speed} for the speed ranges, in Table~\ref{tab:direction} for the heading ranges.

$51.04\%$ of the $x$ offset values belong to the range $[-1.16 \times 10^{-2} \ \degree \ \mathrm{long.}, \ 6.6 \times 10^{-5} \ \degree \ \mathrm{long.}>$. $48.96\%$ of the $x$ offset values belong to the range $[6.6 \times 10^{-5} \ \degree \ \mathrm{long.}, \ 9.45 \times 10^{-3} \ \degree \ \mathrm{long.}]$. 

The $x$ offset values that belong to the range $[-1.16 \times 10^{-2} \ \degree \ \mathrm{long.}, \ 6.6 \times 10^{-5} \ \degree \ \mathrm{long.}>$ have a $98.69\%$ probability of staying in the same range in the next step. The $x$offset values belonging to the range $[6.6 \times 10^{-5} \ \degree \ \mathrm{long.}, \ 9.45 \times 10^{-3} \ \degree \ \mathrm{long.}]$ have a $98.89\%$ probability of remaining in the same range in the next step.

The $x$ offset values belonging to the range $[-1.16 \times 10^{-2} \ \degree \ \mathrm{long.}, \ 6.6 \times 10^{-5} \ \degree \ \mathrm{long.}>$ have a $96.09\%$ probability of staying in the same range if they have been in the range in two consecutive steps. The $x$ offset values belonging to the range $[6.6 \times 10^{-5} \ \degree \ \mathrm{long.}, \ 9.45 \times 10^{-3} \ \degree \ \mathrm{long.}]$ have a $94.82\%$ probability of staying in the same range if they have been in the range for two consecutive steps.

The $x$ offset values that belong to the range $[-1.16 \times 10^{-2} \ \degree \ \mathrm{long.}, \ 6.6 \times 10^{-5} \ \degree \ \mathrm{long.}>$ and transitioned to another range have a probability of $97.63\%$ of remaining in this second range in the next step. The $x$ offset values that belong to the range $[6.6 \times 10^{-5} \ \degree \ \mathrm{long.}, \ 9.45 \times 10^{-3} \ \degree \ \mathrm{long.}]$ and transitioned to another range have a probability of $96.33\%$ of remaining in this second range in the next step. This means that the state before the current state has little influence on the next state.

\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|c|}
\hline
$X_{i}$ & $V_{1}$ & $V_{2}$\\ \hline
$P(X_{i})$ & $51.04\%$ & $48.96\%$\\ \hline
\multicolumn{3}{c}{}\\
\end{tabular}

\begin{tabular}{|c|c|c|}
\hline
$P(X_{i}|X_{i-1})$ & \multicolumn{2}{|c|}{$X_{i}$}\\ \hline
$X_{i-1}$ & $V_{1}$ & $V_{2}$\\ \hline
$V_{1}$ & $98.69\%$ & $1.31\%$\\ \hline
$V_{2}$ & $1.11\%$ & $98.89\%$\\ \hline
\multicolumn{3}{c}{}\\
\end{tabular}

\begin{tabular}{|c|c|c|c|c|}
\hline
\multirow{3}{*}{$P(X_{i}|X_{i-1},X_{i-2})$} & \multicolumn{4}{|c|}{$X_{i-2}$}\\ \cline{2-5}
 & \multicolumn{2}{|c|}{$V_{1}$} & \multicolumn{2}{|c|}{$V_{2}$}\\ \cline{2-5}
 & \multicolumn{2}{|c|}{$X_{i}$} & \multicolumn{2}{|c|}{$X_{i}$}\\ \hline
$X_{i-1}$ & $V_{1}$ & $V_{2}$ & $V_{1}$ & $V_{2}$\\ \hline
$V_{1}$ & $96.09\%$ & $3.91\%$ & $96.33\%$ & $3.67\%$\\ \hline
$V_{2}$ & $2.37\%$ & $97.63\%$ & $5.18\%$ & $94.82\%$\\ \hline
\multicolumn{5}{c}{}\\
\multicolumn{5}{c}{$V_{1} = [-1.16 \times 10^{-2} \ \degree \  \mathrm{long.}, 6.6 \times 10^{-5} \ \degree \  \mathrm{long.}>$}\\
\multicolumn{5}{c}{$V_{2} = [6.6 \times 10^{-5} \ \degree \  \mathrm{long.}, 9.45 \times 10^{-3} \ \degree \  \mathrm{long.}]$}\\
\end{tabular}
\caption{The frequency and the transition matrix for the first and second order Markov chain for $x$ offset ranges.}
\label{tab:longitude_no_abs}
\end{table}

$50.15\%$ of the $y$ offset values belong to the range $[-4.78 \times 10^{-3} \ \degree \ \mathrm{lat.}, \ 1.7 \times 10^{-5} \ \degree \ \mathrm{lat.}>$. $49.85\%$ of the $y$ offset values are in the range $[1.7 \times 10^{-5} \ \degree \ \mathrm{lat.}, \ 2.12 \times 10^{-2} \ \degree \ \mathrm{lat.}]$.

The $y$ offset values that belong to the range $[-4.78 \times 10^{-3} \ \degree \ \mathrm{lat.}, \ 1.7 \times 10^{-5} \ \degree \ \mathrm{lat.}>$ have a $98.46\%$ probability of remaining in the same range in the next step. The $y$ offset values that belong to the range $[1.7 \times 10^{-5} \ \degree \ \mathrm{lat.}, \ 2.12 \times 10^{-2} \ \degree \ \mathrm{lat.}]$ have a $97.94\%$ probability of remaining in the same range in the next step. 

The $y$ offset values belonging to the range $[-4.78 \times 10^{-3} \ \degree \ \mathrm{lat.}, \ 1.7 \times 10^{-5} \ \degree \ \mathrm{lat.}>$ have a $96.77\%$ probability of remaining in the same range if they have been in the range in two consecutive steps. The $y$ offset values belonging to the range $[1.7 \times 10^{-5} \ \degree \ \mathrm{lat.}, \ 2.12 \times 10^{-2} \ \degree \ \mathrm{lat.}]$ have a $96.45\%$ probability of staying in the same range if they have been in the range for two consecutive steps.

The $y$ offset values that belong to the range $[-4.78 \times 10^{-3} \ \degree \ \mathrm{lat.}, \ 1.7 \times 10^{-5} \ \degree \ \mathrm{lat.}>$ and have moved to another range have a probability of $86.96\%$ of remaining in that second range in the next step. The $y$ offset values that belong to the range $[1.7 \times 10^{-5} \ \degree \ \mathrm{lat.}, \  2.12 \times 10^{-2} \ \degree \ \mathrm{lat.}]$ and transitioned to another range have a probability of $96.43\%$ of remaining in that second range in the next step. This means that the state before the current state has little impact on the next state.

\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|c|}
\hline
$X_{i}$ & $V_{1}$ & $V_{2}$\\ \hline
$P(X_{i})$ & $50.15\%$ & $49.85\%$\\ \hline
\multicolumn{3}{c}{}\\
\end{tabular}

\begin{tabular}{|c|c|c|}
\hline
$P(X_{i}|X_{i-1})$ & \multicolumn{2}{|c|}{$X_{i}$}\\ \hline
$X_{i-1}$ & $V_{1}$ & $V_{2}$\\ \hline
$V_{1}$ & $98.46\%$ & $1.54\%$\\ \hline
$V_{2}$ & $2.06\%$ & $97.94\%$\\ \hline
\multicolumn{3}{c}{}\\
\end{tabular}

\begin{tabular}{|c|c|c|c|c|}
\hline
\multirow{3}{*}{$P(X_{i}|X_{i-1},X_{i-2})$} & \multicolumn{4}{|c|}{$X_{i-2}$}\\ \cline{2-5}
 & \multicolumn{2}{|c|}{$V_{1}$} & \multicolumn{2}{|c|}{$V_{2}$}\\ \cline{2-5}
 & \multicolumn{2}{|c|}{$X_{i}$} & \multicolumn{2}{|c|}{$X_{i}$}\\ \hline
$X_{i-1}$ & $V_{1}$ & $V_{2}$ & $V_{1}$ & $V_{2}$\\ \hline
$V_{1}$ & $96.77\%$ & $3.23\%$ & $96.43\%$ & $3.57\%$\\ \hline
$V_{2}$ & $13.04\%$ & $86.96\%$ & $3.55\%$ & $96.45\%$\\ \hline
\multicolumn{5}{c}{}\\
\multicolumn{5}{c}{$V_{1} = [-4.78 \times 10^{-3} \ \degree \  \mathrm{lat.}, 1.7 \times 10^{-5} \ \degree \  \mathrm{lat.}>$}\\
\multicolumn{5}{c}{$V_{2} = [1.7 \times 10^{-5} \ \degree \  \mathrm{lat.}, 2.12 \times 10^{-2} \ \degree \  \mathrm{lat.}]$}\\
\end{tabular}
\caption{The frequency and the transition matrix for the first and second order Markov chain for $y$ offset ranges.}
\label{tab:latitude_no_abs}
\end{table}

$50.7\%$ of the speed values belong to the range $[0 \ km/h, \ 18 \ km/h>$. $49.3\%$ of the speed values belong to the range $[18 \ km/h, \ 83 \ km/h]$.

The speed values that belong to the range $[0 \ km/h, \ 18 \ km/h>$ have a probability of $94.19\%$ of remaining in the same range in the next step. The speed values belonging to the range $[18 \ km/h, \ 83 \ km/h]$ have a probability of $98.06\%$ of remaining in the same range in the next step.

The speed values belonging to the range $[0 \ km/h, \ 18 \ km/h>$ have a probability of $96.66\%$ of remaining in the same range if they were in this range in two consecutive steps. The speed values belonging to the range $[18 \ km/h, \ 83 \ km/h]$ have a probability of $95.75\%$ of remaining in the same range if they have been in the range for two consecutive steps.

The speed values that belong to the range $[0 \ km/h, \ 18 \ km/h>$ and pass into another range have a probability of $99.99\%$ of remaining in this second range in the next step. The speed values that belong to the range $[18 \ km/h, \ 83 \ km/h]$ and transition to another range have a probability of $91.82\%$ of remaining in that second range in the next step. This means that the state before the current state has little influence on the next state.

\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|c|}
\hline
$X_{i}$ & $V_{1}$ & $V_{2}$\\ \hline
$P(X_{i})$ & $50.7\%$ & $49.3\%$\\ \hline
\multicolumn{3}{c}{}\\
\end{tabular}

\begin{tabular}{|c|c|c|}
\hline
$P(X_{i}|X_{i-1})$ & \multicolumn{2}{|c|}{$X_{i}$}\\ \hline
$X_{i-1}$ & $V_{1}$ & $V_{2}$\\ \hline
$V_{1}$ & $94.19\%$ & $5.81\%$\\ \hline
$V_{2}$ & $1.94\%$ & $97.96\%$\\ \hline
\multicolumn{3}{c}{}\\
\end{tabular}

\begin{tabular}{|c|c|c|c|c|}
\hline
\multirow{3}{*}{$P(X_{i}|X_{i-1},X_{i-2})$} & \multicolumn{4}{|c|}{$X_{i-2}$}\\ \cline{2-5}
 & \multicolumn{2}{|c|}{$V_{1}$} & \multicolumn{2}{|c|}{$V_{2}$}\\ \cline{2-5}
 & \multicolumn{2}{|c|}{$X_{i}$} & \multicolumn{2}{|c|}{$X_{i}$}\\ \hline
$X_{i-1}$ & $V_{1}$ & $V_{2}$ & $V_{1}$ & $V_{2}$\\ \hline
$V_{1}$ & $96.66\%$ & $3.34\%$ & $91.82\%$ & $8.18\%$\\ \hline
$V_{2}$ & $96.66\%$ & $3.34\%$ & $4.25\%$ & $95.75\%$\\ \hline
\multicolumn{5}{c}{}\\
\multicolumn{5}{c}{$V_{1} = [0 \ km/h, 18 \ km/h>$}\\
\multicolumn{5}{c}{$V_{2} = [18 \ km/h, \ 83 \ km/h]$}\\
\end{tabular}
\caption{The frequency and the transition matrix for the first and second order Markov chain for speed ranges.}
\label{tab:speed}
\end{table}

$47.68\%$ of the heading values belong to the range $[0 \degree, \ 180 \degree>$. $52.32\%$ of the heading values belong to the range $[180 \degree, \ 360 \degree]$.

The heading values that belong to the range $[0 \degree, \ 180 \degree>$ have a probability of $96.27\%$ that they will remain in the same range in the next step. The heading values that belong to the range $[180 \degree, \ 360 \degree]$ have a probability of $96.43\%$ of remaining in the same range in the next step.

The heading values that belong to the range $[0 \degree, \ 180 \degree>$ have a probability of $95.44\%$ of remaining in the same range if they have been in the range in two consecutive steps. The heading values belonging to the range $[180 \degree, \ 360 \degree]$ have a probability of $90.59\%$ of staying in the same range if they have been in the range for two consecutive steps.

The heading values that belong to the range $[0 \degree, \ 180 \degree>$ and have moved to another range have a probability of $96.75\%$ of staying in that second range in the next step. The heading values that belong to the range $[180 \degree, \ 360 \degree]$ and move to another range have a probability of $99.99\%$ of remaining in this second range in the next step. This means that the state before the current state has little influence on the next state.

\begin{table}[!ht]
\centering
\begin{tabular}{|c|c|c|}
\hline
$X_{i}$ & $V_{1}$ & $V_{2}$\\ \hline
$P(X_{i})$ & $47.68\%$ & $52.32\%$\\ \hline
\multicolumn{3}{c}{}\\
\end{tabular}

\begin{tabular}{|c|c|c|}
\hline
$P(X_{i}|X_{i-1})$ & \multicolumn{2}{|c|}{$X_{i}$}\\ \hline
$X_{i-1}$ & $V_{1}$ & $V_{2}$\\ \hline
$V_{1}$ & $96.27\%$ & $3.72\%$\\ \hline
$V_{2}$ & $3.57\%$ & $96.43\%$\\ \hline
\multicolumn{3}{c}{}\\
\end{tabular}

\begin{tabular}{|c|c|c|c|c|}
\hline
\multirow{3}{*}{$P(X_{i}|X_{i-1},X_{i-2})$} & \multicolumn{4}{|c|}{$X_{i-2}$}\\ \cline{2-5}
 & \multicolumn{2}{|c|}{$V_{1}$} & \multicolumn{2}{|c|}{$V_{2}$}\\ \cline{2-5}
 & \multicolumn{2}{|c|}{$X_{i}$} & \multicolumn{2}{|c|}{$X_{i}$}\\ \hline
$X_{i-1}$ & $V_{1}$ & $V_{2}$ & $V_{1}$ & $V_{2}$\\ \hline
$V_{1}$ & $95.44\%$ & $4.56\%$ & $99.99\%$ & $0.01\%$\\ \hline
$V_{2}$ & $3.25\%$ & $96.75\%$ & $9.41\%$ & $90.59\%$\\ \hline
\multicolumn{5}{c}{}\\
\multicolumn{5}{c}{$V_{1} = [0 \degree, 180 \degree>$}\\
\multicolumn{5}{c}{$V_{2} = [180 \degree, 360 \degree]$}\\
\end{tabular}
\caption{The frequency and the transition matrix for the first and second order Markov chain for heading ranges.}
\label{tab:direction}
\end{table}

\begin{thebibliography}{101}
% BibTex style file: bmc-mathphys.bst (version 2.1), 2014-07-24
\ifx \bisbn   \undefined \def \bisbn  #1{ISBN #1}\fi
\ifx \binits  \undefined \def \binits#1{#1}\fi
\ifx \bauthor  \undefined \def \bauthor#1{#1}\fi
\ifx \batitle  \undefined \def \batitle#1{#1}\fi
\ifx \bjtitle  \undefined \def \bjtitle#1{\textit{#1}}\fi
\ifx \bvolume  \undefined \def \bvolume#1{\textit{#1}}\fi
\ifx \byear  \undefined \def \byear#1{#1}\fi
\ifx \bissue  \undefined \def \bissue#1{#1}\fi
\ifx \bfpage  \undefined \def \bfpage#1{#1}\fi
\ifx \blpage  \undefined \def \blpage #1{#1}\fi
\ifx \burl  \undefined \def \burl#1{\textsf{#1}}\fi
\ifx \doiurl  \undefined \def \doiurl#1{\url{https://doi.org/#1}}\fi
\ifx \betal  \undefined \def \betal{\textit{et al.}}\fi
\ifx \binstitute  \undefined \def \binstitute#1{#1}\fi
\ifx \binstitutionaled  \undefined \def \binstitutionaled#1{#1}\fi
\ifx \bctitle  \undefined \def \bctitle#1{#1}\fi
\ifx \beditor  \undefined \def \beditor#1{#1}\fi
\ifx \bpublisher  \undefined \def \bpublisher#1{#1}\fi
\ifx \bbtitle  \undefined \def \bbtitle#1{\textit{#1}}\fi
\ifx \bedition  \undefined \def \bedition#1{#1}\fi
\ifx \bseriesno  \undefined \def \bseriesno#1{#1}\fi
\ifx \blocation  \undefined \def \blocation#1{#1}\fi
\ifx \bsertitle  \undefined \def \bsertitle#1{#1}\fi
\ifx \bsnm \undefined \def \bsnm#1{#1}\fi
\ifx \bsuffix \undefined \def \bsuffix#1{#1}\fi
\ifx \bparticle \undefined \def \bparticle#1{#1}\fi
\ifx \barticle \undefined \def \barticle#1{#1}\fi
%\bibcommenthead
\ifx \bconfdate \undefined \def \bconfdate #1{#1}\fi
\ifx \botherref \undefined \def \botherref #1{#1}\fi
\ifx \url \undefined \def \url#1{\textsf{#1}}\fi
\ifx \bchapter \undefined \def \bchapter#1{#1}\fi
\ifx \bbook \undefined \def \bbook#1{#1}\fi
\ifx \bcomment \undefined \def \bcomment#1{#1}\fi
\ifx \oauthor \undefined \def \oauthor#1{#1}\fi
\ifx \citeauthoryear \undefined \def \citeauthoryear#1{#1}\fi
\ifx \endbibitem  \undefined \def \endbibitem {}\fi
\ifx \bconflocation  \undefined \def \bconflocation#1{#1}\fi
\ifx \arxivurl  \undefined \def \arxivurl#1{\textsf{#1}}\fi
\csname PreBibitemsHook\endcsname

%%% 1
\bibitem{2022Kim}
\begin{barticle}
\bauthor{\bsnm{Kim}, \binits{Y.J.}},
\bauthor{\bsnm{Lee}, \binits{J.S.}},
\bauthor{\bsnm{Pititto}, \binits{A.}},
\bauthor{\bsnm{Falco}, \binits{L.}},
\bauthor{\bsnm{Lee}, \binits{M.S.}},
\bauthor{\bsnm{Yoon}, \binits{K.K.}}, \&
\bauthor{\bsnm{Cho}, \binits{I.S.}}
(\byear{2022}).
\batitle{{M}aritime {T}raffic {E}valuation {U}sing {S}patial-{T}emporal {D}ensity {A}nalysis {B}ased on {B}ig {A}{I}{S} {D}ata}.
\bjtitle{Applied Sciences},
\bvolume{12}.
doi:10.3390/app122111246.
\end{barticle}
\endbibitem

%%% 2
\bibitem{2013Kazemi}
\begin{barticle}
\bauthor{\bsnm{Kazemi}, \binits{S.}},
\bauthor{\bsnm{Abghari}, \binits{S.}},
\bauthor{\bsnm{Lavesson}, \binits{N.}},
\bauthor{\bsnm{Johnson}, \binits{H.}}, \&
\bauthor{\bsnm{Ryman}, \binits{P.}}
(\byear{2013}).
\batitle{{O}pen data for anomaly detection in maritime surveillance}.
\bjtitle{Expert Systems with Applications},
\bvolume{40},
\bfpage{5719}--\bfpage{5729}.
doi:10.1016/j.eswa.2013.04.029.
\end{barticle}
\endbibitem

%%% 3
\bibitem{2009Chandola}
\begin{barticle}
\bauthor{\bsnm{Chandola}, \binits{V.}},
\bauthor{\bsnm{Banerjee}, \binits{A.}}, \&
\bauthor{\bsnm{Kumar}, \binits{V.}}
(\byear{2009}).
\batitle{{A}nomaly {D}etection: {A} {S}urvey}.
\bjtitle{ACM Comput. Surv.},
\bvolume{41}.
doi:10.1145/1541880.1541882.
\end{barticle}
\endbibitem

%%% 4
\bibitem{2011Martineau}
\begin{barticle}
\bauthor{\bsnm{Martineau}, \binits{E.}}, \&
\bauthor{\bsnm{Roy}, \binits{J.}}
(\byear{2011}).
\batitle{{M}aritime {A}nomaly {D}etection: {D}omain {I}ntroduction and {R}eview of {S}elected {L}iterature}.
\bjtitle{DEFENCE RESEARCH AND DEVELOPMENT CANADA VALCARTIER (QUEBEC)}.
\end{barticle}
\endbibitem

%%% 5
\bibitem{2008Roy}
\begin{barticle}
\bauthor{\bsnm{Roy}, \binits{J.}}
(\byear{2008}).
\batitle{{A}nomaly detection in the maritime domain}.
\bjtitle{Proc SPIE}.
doi:10.1117/12.776230.
\end{barticle}
\endbibitem

%%% 6
\bibitem{2014Mascaro}
\begin{barticle}
\bauthor{\bsnm{Mascaro}, \binits{S.}},
\bauthor{\bsnm{Nicholso}, \binits{A.}}, \&
\bauthor{\bsnm{Korb}, \binits{K.}}
(\byear{2014}).
\batitle{{A}nomaly detection in vessel tracks using {B}ayesian networks}.
\bjtitle{International Journal of Approximate Reasoning},
\bvolume{55},
\bfpage{84}--\bfpage{98}.
doi:10.1016/j.ijar.2013.03.012.
\end{barticle}
\endbibitem

%%% 7
\bibitem{2008Laxhammar}
\begin{bchapter}
\bauthor{\bsnm{Laxhammar}, \binits{R.}}
(\byear{2008}).
\bctitle{{A}nomaly detection for sea surveillance}.
In \bbtitle{2008 11th {I}nternational {C}onference on {I}nformation {F}usion}
(pp. \bfpage{1}--\bfpage{8}).
\end{bchapter}
\endbibitem

%%% 8
\bibitem{ototrakOtoTrakTrack}
\begin{botherref}
\oauthor{\bsnm{OtoTrak}}
(\byear{2024}).
{O}to{T}rak - {T}rack your watercraft --- ototrak.com.
\url{https://www.ototrak.com/en-us}.
Accessed 15 November 2024.
\end{botherref}
\endbibitem

%%% 9
\bibitem{2016Coraluppi}
\begin{bchapter}
\bauthor{\bsnm{Coraluppi}, \binits{S.}},
\bauthor{\bsnm{Carthel}, \binits{C.}},
\bauthor{\bsnm{Braca}, \binits{P.}}, \&
\bauthor{\bsnm{Millefiori}, \binits{L.}}
(\byear{2016}).
\bctitle{{T}he {M}ixed {O}rnstein-{U}hlenbeck {P}rocess and context exploitation in multi-target tracking}.
In \bbtitle{2016 19th {I}nternational {C}onference on {I}nformation {F}usion ({F}{U}{S}{I}{O}{N})}
(pp. \bfpage{217}--\bfpage{224}).
\end{bchapter}
\endbibitem

%%% 10
\bibitem{2018dAfflisio1}
\begin{barticle}
\bauthor{\bsnm{d'Afflisio}, \binits{E.}},
\bauthor{\bsnm{Braca}, \binits{P.}},
\bauthor{\bsnm{Millefiori}, \binits{L.M.}}, \&
\bauthor{\bsnm{Willett}, \binits{P.}}
(\byear{2018}).
\batitle{{D}etecting {A}nomalous {D}eviations {F}rom {S}tandard {M}aritime {R}outes {U}sing the {O}rnstein-{U}hlenbeck {P}rocess}.
\bjtitle{IEEE Transactions on Signal Processing},
\bvolume{66},
\bfpage{6474}--\bfpage{6487}.
doi:10.1109/TSP.2018.2875887.
\end{barticle}
\endbibitem

%%% 11
\bibitem{2018Coscia}
\begin{barticle}
\bauthor{\bsnm{Coscia}, \binits{P.}},
\bauthor{\bsnm{Braca}, \binits{P.}},
\bauthor{\bsnm{Millefiori}, \binits{L.M.}},
\bauthor{\bsnm{Palmieri}, \binits{F.A.N.}}, \&
\bauthor{\bsnm{Willett}, \binits{P.}}
(\byear{2018}).
\batitle{{M}ultiple {O}rnstein-{U}hlenbeck {P}rocesses for {M}aritime {T}raffic {G}raph {R}epresentation}.
\bjtitle{IEEE Transactions on Aerospace and Electronic Systems},
\bvolume{54},
\bfpage{2158}--\bfpage{2170}.
doi:10.1109/TAES.2018.2808098.
\end{barticle}
\endbibitem

%%% 12
\bibitem{2018Coscia1}
\begin{barticle}
\bauthor{\bsnm{Coscia}, \binits{P.}},
\bauthor{\bsnm{Palmieri}, \binits{F.A.N.}},
\bauthor{\bsnm{Braca}, \binits{P.}},
\bauthor{\bsnm{Millefiori}, \binits{L.M.}}, \&
\bauthor{\bsnm{Willett}, \binits{P.}}
(\byear{2018}).
\batitle{{U}nsupervised {M}aritime {T}raffic {G}raph {L}earning with {M}ean-{R}everting {S}tochastic {P}rocesses}.
\bjtitle{2018 21st International Conference on Information Fusion (FUSION)}.
doi:10.23919/icif.2018.8455392.
\end{barticle}
\endbibitem

%%% 13
\bibitem{2018Forti}
\begin{barticle}
\bauthor{\bsnm{Forti}, \binits{N.}},
\bauthor{\bsnm{Millefiori}, \binits{L.M.}}, \&
\bauthor{\bsnm{Braca}, \binits{P.}}
(\byear{2018}).
\batitle{{H}ybrid {B}ernoulli {F}iltering for {D}etection and {T}racking of {A}nomalous {P}ath {D}eviations}.
\bjtitle{2018 21st International Conference on Information Fusion (FUSION)}.
doi:10.23919/icif.2018.8455567.
\end{barticle}
\endbibitem

%%% 14
\bibitem{2019Forti}
\begin{barticle}
\bauthor{\bsnm{Forti}, \binits{N.}},
\bauthor{\bsnm{Millefiori}, \binits{L.M.}},
\bauthor{\bsnm{Braca}, \binits{P.}}, \&
\bauthor{\bsnm{Willett}, \binits{P.}}
(\byear{2019}).
\batitle{{A}nomaly {D}etection and {T}racking {B}ased on {M}ean-{R}everting {P}rocesses with {U}nknown {P}arameters}.
\bjtitle{ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}.
doi:10.1109/icassp.2019.8683428.
\end{barticle}
\endbibitem

%%% 15
\bibitem{2020Forti}
\begin{bchapter}
\bauthor{\bsnm{Forti}, \binits{N.}},
\bauthor{\bsnm{Millefiori}, \binits{L.M.}},
\bauthor{\bsnm{Braca}, \binits{P.}}, \&
\bauthor{\bsnm{Willett}, \binits{P.}}
(\byear{2020}).
\bctitle{{R}andom {F}inite {S}et {T}racking for {A}nomaly {D}etection in the {P}resence of {C}lutter}.
In \bbtitle{2020 {I}{E}{E}{E} {R}adar {C}onference ({R}adar{C}onf20)}
(pp. \bfpage{1}--\bfpage{6}).
doi:10.1109/RadarConf2043947.2020.9266705.
\end{bchapter}
\endbibitem

%%% 16
\bibitem{2022Forti2}
\begin{barticle}
\bauthor{\bsnm{Forti}, \binits{N.}},
\bauthor{\bsnm{d'Afflisio}, \binits{E.}},
\bauthor{\bsnm{Braca}, \binits{P.}},
\bauthor{\bsnm{Millefiori}, \binits{L.M.}},
\bauthor{\bsnm{Carniel}, \binits{S.}}, \&
\bauthor{\bsnm{Willett}, \binits{P.}}
(\byear{2022}).
\batitle{{N}ext-{G}en {I}ntelligent {S}ituational {A}wareness {S}ystems for {M}aritime {S}urveillance and {A}utonomous {N}avigation [{P}oint of {V}iew]}.
\bjtitle{Proceedings of the IEEE},
\bvolume{110}.
doi:10.1109/jproc.2022.3194445.
\end{barticle}
\endbibitem

%%% 17
\bibitem{2016Millefiori}
\begin{barticle}
\bauthor{\bsnm{Millefiori}, \binits{L.}},
\bauthor{\bsnm{Braca}, \binits{P.}},
\bauthor{\bsnm{Bryan}, \binits{K.}}, \&
\bauthor{\bsnm{Willett}, \binits{P.}}
(\byear{2016}).
\batitle{{M}odeling {V}essel {K}inematics {U}sing a {S}tochastic {M}ean-{R}everting {P}rocess for {L}ong-{T}erm {P}rediction}.
\bjtitle{IEEE Transactions on Aerospace and Electronic Systems},
\bvolume{52}.
doi:10.1109/TAES.2016.150596.
\end{barticle}
\endbibitem

%%% 18
\bibitem{2021dAfflisio}
\begin{barticle}
\bauthor{\bsnm{d'Afflisio}, \binits{E.}},
\bauthor{\bsnm{Braca}, \binits{P.}},
\bauthor{\bsnm{Chisci}, \binits{L.}},
\bauthor{\bsnm{Battistelli}, \binits{G.}}, \&
\bauthor{\bsnm{Willett}, \binits{P.}}
(\byear{2021}).
\batitle{{M}aritime {A}nomaly {D}etection of {M}alicious {D}ata {S}poofing and {S}tealth {D}eviations from {N}ominal {R}oute {E}xploiting {H}eterogeneous {S}ources of {I}nformation}.
\bjtitle{2021 IEEE 24th International Conference on Information Fusion (FUSION)}.
doi:10.23919/fusion49465.2021.9627049.
\end{barticle}
\endbibitem

%%% 19
\bibitem{2021dAfflisio1}
\begin{barticle}
\bauthor{\bsnm{d'Afflisio}, \binits{E.}},
\bauthor{\bsnm{Braca}, \binits{P.}}, \&
\bauthor{\bsnm{Willett}, \binits{P.}}
(\byear{2021}).
\batitle{{M}alicious {A}{I}{S} {S}poofing and {A}bnormal {S}tealth {D}eviations: {A} {C}omprehensive {S}tatistical {F}ramework for {M}aritime {A}nomaly {D}etection}.
\bjtitle{IEEE Transactions on Aerospace and Electronic Systems},
\bvolume{57}.
doi:10.1109/taes.2021.3083466.
\end{barticle}
\endbibitem

%%% 20
\bibitem{10130587}
\begin{barticle}
\bauthor{\bsnm{Zhu}, \binits{S.}},
\bauthor{\bsnm{Cao}, \binits{J.}},
\bauthor{\bsnm{Lin}, \binits{L.}},
\bauthor{\bsnm{Rutkowski}, \binits{L.}},
\bauthor{\bsnm{Lu}, \binits{J.}}, \&
\bauthor{\bsnm{Lu}, \binits{G.}}
(\byear{2023}).
\batitle{{O}bservability and {D}etectability of {S}tochastic {L}abeled {G}raphs}.
\bjtitle{IEEE Transactions on Automatic Control},
\bvolume{68},
\bfpage{7299}--\bfpage{7311}.
doi:10.1109/TAC.2023.3278797.
\end{barticle}
\endbibitem

%%% 21
\bibitem{10106394}
\begin{barticle}
\bauthor{\bsnm{Zhu}, \binits{S.}},
\bauthor{\bsnm{Cao}, \binits{J.}},
\bauthor{\bsnm{Lin}, \binits{L.}},
\bauthor{\bsnm{Lam}, \binits{J.}}, \&
\bauthor{\bsnm{Azuma}, \binits{S.}}
(\byear{2024}).
\batitle{{T}oward {S}tabilizable {L}arge-{S}cale {B}oolean {N}etworks by {C}ontrolling the {M}inimal {S}et of {N}odes}.
\bjtitle{IEEE Transactions on Automatic Control},
\bvolume{69},
\bfpage{174}--\bfpage{188}.
doi:10.1109/TAC.2023.3269321.
\end{barticle}
\endbibitem

%%% 22
\bibitem{10309224}
\begin{barticle}
\bauthor{\bsnm{Zhu}, \binits{S.}},
\bauthor{\bsnm{Lu}, \binits{J.}},
\bauthor{\bsnm{Ho}, \binits{D.W.C.}}, \&
\bauthor{\bsnm{Cao}, \binits{J.}}
(\byear{2024}).
\batitle{{M}inimal {C}ontrol {N}odes for {S}trong {S}tructural {O}bservability of {D}iscrete-{T}ime {I}terative {S}ystems: {E}xplicit {F}ormulas and {P}olynomial-{T}ime {A}lgorithms}.
\bjtitle{IEEE Transactions on Automatic Control},
\bvolume{69},
\bfpage{2158}--\bfpage{2173}.
doi:10.1109/TAC.2023.3330263.
\end{barticle}
\endbibitem

%%% 23
\bibitem{2020FortiO}
\begin{barticle}
\bauthor{\bsnm{Forti}, \binits{N.}},
\bauthor{\bsnm{d'Afflisio}, \binits{E.}},
\bauthor{\bsnm{Braca}, \binits{P.}},
\bauthor{\bsnm{Millefiori}, \binits{L.M.}},
\bauthor{\bsnm{Willett}, \binits{P.}}, \&
\bauthor{\bsnm{Carniel}, \binits{S.}}
(\byear{2022}).
\batitle{{M}aritime {A}nomaly {D}etection in a {R}eal-{W}orld {S}cenario: {E}ver {G}iven {G}rounding in the {S}uez {C}anal}.
\bjtitle{IEEE Transactions on Intelligent Transportation Systems},
\bvolume{23},
\bfpage{13904}--\bfpage{13910}.
doi:10.1109/TITS.2021.3123890.
\end{barticle}
\endbibitem

%%% 24
\bibitem{2022FortiO}
\begin{barticle}
\bauthor{\bsnm{Forti}, \binits{N.}},
\bauthor{\bsnm{d'Afflisio}, \binits{E.}},
\bauthor{\bsnm{Braca}, \binits{P.}},
\bauthor{\bsnm{Millefiori}, \binits{L.M.}},
\bauthor{\bsnm{Willett}, \binits{P.}}, \&
\bauthor{\bsnm{Carniel}, \binits{S.}}
(\byear{2022}).
\batitle{{M}aritime {A}nomaly {D}etection in a {R}eal-{W}orld {S}cenario: {E}ver {G}iven {G}rounding in the {S}uez {C}anal}.
\bjtitle{IEEE Transactions on Intelligent Transportation Systems},
\bvolume{23},
\bfpage{13904}--\bfpage{13910}.
doi:10.1109/TITS.2021.3123890.
\end{barticle}
\endbibitem

%%% 25
\bibitem{2022Forti1}
\begin{barticle}
\bauthor{\bsnm{Forti}, \binits{N.}},
\bauthor{\bsnm{Millefiori}, \binits{L.M.}},
\bauthor{\bsnm{Braca}, \binits{P.}}, \&
\bauthor{\bsnm{Willett}, \binits{P.}}
(\byear{2022}).
\batitle{{B}ayesian {F}iltering for {D}ynamic {A}nomaly {D}etection and {T}racking}.
\bjtitle{IEEE Transactions on Aerospace and Electronic Systems},
\bvolume{58}.
doi:10.1109/TAES.2021.3122888.
\end{barticle}
\endbibitem

%%% 26
\bibitem{2016Ning}
\begin{barticle}
\bauthor{\bsnm{Ning}, \binits{J.}}
(\byear{2016}).
\batitle{{S}tudy on {M}aritime traffic density calculation and maritime hotspots discovery based on {A}{I}{S} data}.
\bjtitle{Special Issue of Applied Sciences "Transportation Big Data and Its Applications", section "Computing and Artificial Intelligence"}.
\end{barticle}
\endbibitem

%%% 27
\bibitem{Ester1996ADA}
\begin{barticle}
\bauthor{\bsnm{Ester}, \binits{M.}},
\bauthor{\bsnm{Kriegel}, \binits{H.P.}},
\bauthor{\bsnm{Sander}, \binits{J.}}, \&
\bauthor{\bsnm{Xu}, \binits{X.}}
(\byear{1996}).
\batitle{{A} {D}ensity-{B}ased {A}lgorithm for {D}iscovering {C}lusters in {L}arge {S}patial {D}atabases with {N}oise}.
\bjtitle{Knowledge Discovery and Data Mining},
\bvolume{96},
\bfpage{226}--\bfpage{231}.
doi:10.5120/739-1038.
\end{barticle}
\endbibitem

%%% 28
\bibitem{Khan2004RealtimePO}
\begin{bchapter}
\bauthor{\bsnm{Khan}, \binits{A.}},
\bauthor{\bsnm{Bil}, \binits{C.}},
\bauthor{\bsnm{Marion}, \binits{K.E.}}, \&
\bauthor{\bsnm{Crozier}, \binits{M.}}
(\byear{2004}).
\bctitle{{R}eal-time prediction of ship motion and attitude using advanced prediction techniques}.
In \bbtitle{24th {I}nternational {C}ongress of the {A}eronautical {S}ciences}.
\end{bchapter}
\endbibitem

%%% 29
\bibitem{2021Pedroche}
\begin{barticle}
\bauthor{\bsnm{Pedroche}, \binits{D.S.}},
\bauthor{\bsnm{Herrero}, \binits{D.A.}},
\bauthor{\bsnm{Herrero}, \binits{J.G.}}, \&
\bauthor{\bsnm{Lopez}, \binits{J.M.M.}}
(\byear{2021}).
\batitle{{C}lustering of maritime trajectories with {A}{I}{S} features for context learning}.
\bjtitle{2021 IEEE 24th International Conference on Information Fusion (FUSION)}.
doi:10.23919/fusion49465.2021.9626956.
\end{barticle}
\endbibitem

%%% 30
\bibitem{2013Pallotta}
\begin{barticle}
\bauthor{\bsnm{Pallotta}, \binits{G.}},
\bauthor{\bsnm{Vespe}, \binits{M.}}, \&
\bauthor{\bsnm{Bryan}, \binits{K.}}
(\byear{2013}).
\batitle{{V}essel {P}attern {K}nowledge {D}iscovery from {A}{I}{S} {D}ata: {A} {F}ramework for {A}nomaly {D}etection and {R}oute {P}rediction}.
\bjtitle{Entropy},
\bvolume{15},
\bfpage{2218}--\bfpage{2245}.
doi:10.3390/e15062218.
\end{barticle}
\endbibitem

%%% 31
\bibitem{2020Loi}
\begin{bchapter}
\bauthor{\bsnm{Loi}, \binits{N.V.}},
\bauthor{\bsnm{Trung}, \binits{K.T.}},
\bauthor{\bsnm{Hop}, \binits{T.V.}},
\bauthor{\bsnm{Thanh}, \binits{S.L.}}, \&
\bauthor{\bsnm{Khuong}, \binits{N.V.}}
(\byear{2020}).
\bctitle{{A}bnormal {M}oving {S}peed {D}etection {U}sing {C}ombination of {K}ernel {D}ensity {E}stimator and {D}{B}{S}{C}{A}{N} for {C}oastal {S}urveillance {R}adars}.
In \bbtitle{2020 7th {I}nternational {C}onference on {S}ignal {P}rocessing and {I}ntegrated {N}etworks ({S}{P}{I}{N})}
(pp. \bfpage{143}--\bfpage{147}).
doi:10.1109/SPIN48934.2020.9070885.
\end{bchapter}
\endbibitem

%%% 32
\bibitem{2014Pallotta}
\begin{bchapter}
\bauthor{\bsnm{Pallotta}, \binits{G.}},
\bauthor{\bsnm{Horn}, \binits{S.}},
\bauthor{\bsnm{Braca}, \binits{P.}}, \&
\bauthor{\bsnm{Bryan}, \binits{K.}}
(\byear{2014}).
\bctitle{{C}ontext-enhanced vessel prediction based on {O}rnstein-{U}hlenbeck processes using historical {A}{I}{S} traffic patterns: {R}eal-world experimental results}.
In \bbtitle{17th {I}nternational {C}onference on {I}nformation {F}usion ({F}{U}{S}{I}{O}{N})}
(pp. \bfpage{1}--\bfpage{7}).
\end{bchapter}
\endbibitem

%%% 33
\bibitem{Varlamis2019ANA}
\begin{bchapter}
\bauthor{\bsnm{Varlamis}, \binits{I.}},
\bauthor{\bsnm{Tserpes}, \binits{K.}},
\bauthor{\bsnm{Etemad}, \binits{M.}},
\bauthor{\bsnm{Junior}, \binits{A.S.}}, \&
\bauthor{\bsnm{Matwin}, \binits{S.}}
(\byear{2019}).
\bctitle{{A} {N}etwork {A}bstraction of {M}ulti-vessel {T}rajectory {D}ata for {D}etecting {A}nomalies}.
In \bbtitle{{E}{D}{B}{T}/{I}{C}{D}{T} {W}orkshops}.
\end{bchapter}
\endbibitem

%%% 34
\bibitem{10681283}
\begin{barticle}
\bauthor{\bsnm{Zong}, \binits{G.}},
\bauthor{\bsnm{Wang}, \binits{Y.}},
\bauthor{\bsnm{Niu}, \binits{B.}},
\bauthor{\bsnm{Su}, \binits{S.F.}}, \&
\bauthor{\bsnm{Shi}, \binits{K.}}
(\byear{2024}).
\batitle{{E}vent-triggered adaptive {N}{N} tracking control for nonlinear systems with asymmetric time-varying output constraints and application to an {A}{U}{V}s}.
\bjtitle{IEEE Transactions on Vehicular Technology},
\bfpage{1}--\bfpage{11}.
doi:10.1109/TVT.2024.3461669.
\end{barticle}
\endbibitem

%%% 35
\bibitem{10681502}
\begin{barticle}
\bauthor{\bsnm{Wang}, \binits{Y.}}, \&
\bauthor{\bsnm{Zong}, \binits{G.}}
(\byear{2024}).
\batitle{{D}ynamic {E}vent-{T}riggered {A}daptive {F}ixed-{T}ime {P}ractical {T}racking {C}ontrol for {N}onlinear {S}ystems {T}hrough {F}unnel {F}unction}.
\bjtitle{IEEE Transactions on Automation Science and Engineering},
\bfpage{1}--\bfpage{10}.
doi:10.1109/TASE.2024.3458176.
\end{barticle}
\endbibitem

%%% 36
\bibitem{salami2022wind}
\begin{barticle}
\bauthor{\bsnm{Salami}, \binits{A.A.}},
\bauthor{\bsnm{Agbessi}, \binits{P.A.}},
\bauthor{\bsnm{Boureima}, \binits{S.}}, \&
\bauthor{\bsnm{Ajavon}, \binits{A.S.A.}}
(\byear{2022}).
\batitle{{W}ind energy potential estimation using neural network and {S}{V}{R} approaches}.
\bjtitle{Engineering Review},
\bvolume{42},
\bfpage{32}--\bfpage{49}.
doi:10.30765/er.1632.
\end{barticle}
\endbibitem

%%% 37
\bibitem{https://doi.org/10.48670/moi-00022}
\begin{barticle}
\bauthor{\bsnm{{European Union-Copernicus Marine Service}}}
(\byear{2024}).
\batitle{{G}lobal {O}cean {W}aves {R}eanalysis {W}{A}{V}{E}{R}{Y}{S}}.
\bjtitle{E.U. Copernicus Marine Service Information (CMEMS). Marine Data Store (MDS)}.
doi:10.48670/MOI-00022.
\url{http://dx.doi.org/10.48670/MOI-00022}.
Accessed 15 November 2024.
\end{barticle}
\endbibitem

%%% 38
\bibitem{rp5Description}
\begin{botherref}
\oauthor{\bsnm{rp5}}
(\byear{2024}).
{D}efinitions --- rp5.ru.
\url{https://rp5.ru/docs/descript/en}.
Accessed 15 November 2024.
\end{botherref}
\endbibitem

%%% 39
\bibitem{Gagniuc}
\begin{bbook}
\bauthor{\bsnm{Gagniuc}, \binits{P.}}
(\byear{2017}).
\bbtitle{{M}arkov {C}hains: {F}rom {T}heory to {I}mplementation and {E}xperimentation}.
\bpublisher{"Wiley"}.
doi:10.1002/9781119387596.
\end{bbook}
\endbibitem

%%% 40
\bibitem{citeulike:1220946}
\begin{bbook}
\bauthor{\bsnm{{\O}ksendal}, \binits{B.}}
(\byear{2014}).
\bbtitle{{S}tochastic {D}ifferential {E}quations: {A}n {I}ntroduction with {A}pplications ({U}niversitext)}.
\bpublisher{Springer}.
\end{bbook}
\endbibitem

%%% 41
\bibitem{Gagniuc2017-jf}
\begin{bbook}
\bauthor{\bsnm{Gagniuc}, \binits{P.A.}}
(\byear{2017}).
In \bbtitle{{M}arkov chains}
(pp. \bfpage{159}--\bfpage{163}).
\blocation{Nashville, TN}: 
\bpublisher{John Wiley \& Sons}.
\end{bbook}
\endbibitem

%%% 42
\bibitem{Parzen1962-oe}
\begin{bbook}
\bauthor{\bsnm{Parzen}, \binits{E.}}
(\byear{1962}).
\bbtitle{{S}tochastic processes}.
\blocation{San Francisco}: 
\bpublisher{Holden-Day}.
\end{bbook}
\endbibitem

%%% 43
\bibitem{altche2017lstm}
\begin{bchapter}
\bauthor{\bsnm{Altch{\'e}}, \binits{F.}}, \&
\bauthor{\bsnm{de La Fortelle}, \binits{A.}}
(\byear{2017}).
\bctitle{{A}n {L}{S}{T}{M} network for highway trajectory prediction}.
In \bbtitle{2017 {I}{E}{E}{E} 20th international conference on intelligent transportation systems ({I}{T}{S}{C})}
(pp. \bfpage{353}--\bfpage{359}).
doi:10.48550/arXiv.1801.07962.
\end{bchapter}
\endbibitem

%%% 44
\bibitem{liu2014vehicle}
\begin{bchapter}
\bauthor{\bsnm{Liu}, \binits{Q.}},
\bauthor{\bsnm{Lathrop}, \binits{B.}}, \&
\bauthor{\bsnm{Butakov}, \binits{V.}}
(\byear{2014}).
\bctitle{{V}ehicle lateral position prediction: {A} small step towards a comprehensive risk assessment system}.
In \bbtitle{17th {I}nternational {I}{E}{E}{E} {C}onference on {I}ntelligent {T}ransportation {S}ystems ({I}{T}{S}{C})}
(pp. \bfpage{667}--\bfpage{672}).
doi:10.1109/ITSC.2014.6957766.
\end{bchapter}
\endbibitem

\end{thebibliography}

\end{document}